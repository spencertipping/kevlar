#!/usr/bin/perl
# Run perldoc on this file for documentation.

# For the benefit of HTML viewers:
# <div id='cover' style='position: absolute; left: 0; top: 0; width: 10000px; height: 10000px; background: white'></div>

$|++;

my %data;
my %transient;
my %externalized_functions;
my %datatypes;

my %locations;          # Maps eval-numbers to attribute names

sub meta::define_form {
  my ($namespace, $delegate) = @_;
  $datatypes{$namespace} = $delegate;
  *{"meta::${namespace}::implementation"} = $delegate;
  *{"meta::$namespace"} = sub {
    my ($name, $value, %options) = @_;
    chomp $value;
    $data{"${namespace}::$name"} = $value unless $options{no_binding};
    &$delegate($name, $value) unless $options{no_delegate}}}

sub meta::eval_in {
  my ($what, $where) = @_;

  # Obtain next eval-number and alias it to the designated location
  @locations{eval('__FILE__') =~ /\(eval (\d+)\)/} = ($where);

  my $result = eval $what;
  $@ =~ s/\(eval \d+\)/$where/ if $@;
  warn $@ if $@;
  $result}

meta::define_form 'meta', sub {
  my ($name, $value) = @_;
  meta::eval_in($value, "meta::$name")};

meta::meta('configure', <<'__');
# A function to configure transients. Transients can be used to store any number of
# different things, but one of the more common usages is type descriptors.

sub meta::configure {
  my ($datatype, %options) = @_;
  $transient{$_}{$datatype} = $options{$_} for keys %options;
}
__
meta::meta('externalize', <<'__');
# Function externalization. Data types should call this method when defining a function
# that has an external interface.

sub meta::externalize {
  my ($name, $attribute, $implementation) = @_;
  my $escaped = $name;
  $escaped =~ s/[^A-Za-z0-9:]/_/go;
  $externalized_functions{$name} = $externalized_functions{$escaped} = $attribute;
  *{"::$name"} = *{"::$escaped"} = $implementation || $attribute;
}

__
meta::meta('functor::editable', <<'__');
# An editable type. This creates a type whose default action is to open an editor
# on whichever value is mentioned. This can be changed using different flags.

sub meta::functor::editable {
  my ($typename, %options) = @_;

  meta::configure $typename, %options;
  meta::define_form $typename, sub {
    my ($name, $value) = @_;

    $options{on_bind} && &{$options{on_bind}}($name, $value);

    meta::externalize $options{prefix} . $name, "${typename}::$name", sub {
      my $attribute             = "${typename}::$name";
      my ($command, @new_value) = @_;

      return &{$options{default}}(retrieve($attribute)) if ref $options{default} eq 'CODE' and not defined $command;
      return edit($attribute) if $command eq 'edit' or $options{default} eq 'edit' and not defined $command;
      return associate($attribute, @new_value ? join(' ', @new_value) : join('', <STDIN>)) if $command eq '=' or $command eq 'import' or $options{default} eq 'import' and not defined $command;
      return retrieve($attribute)}}}
__
meta::meta('type::alias', <<'__');
meta::configure 'alias', inherit => 0;
meta::define_form 'alias', sub {
  my ($name, $value) = @_;
  meta::externalize $name, "alias::$name", sub {
    # Can't pre-tokenize because shell::tokenize doesn't exist until the library::
    # namespace has been evaluated (which will be after alias::).
    shell::run(shell::tokenize($value), shell::tokenize(@_));
  };
};
__
meta::meta('type::bootstrap', <<'__');
# Bootstrap attributes don't get executed. The reason for this is that because
# they are serialized directly into the header of the file (and later duplicated
# as regular data attributes), they will have already been executed when the
# file is loaded.

meta::configure 'bootstrap', extension => '.pl', inherit => 1;
meta::define_form 'bootstrap', sub {};
__
meta::meta('type::cache', <<'__');
meta::configure 'cache', inherit => 0;
meta::define_form 'cache', \&meta::bootstrap::implementation;
__
meta::meta('type::cached_dependency', <<'__');
meta::configure 'cached_dependency', inherit => 0, extension => '';
meta::define_form 'cached_dependency', \&meta::bootstrap::implementation;
__
meta::meta('type::configuration', <<'__');
meta::functor::editable 'configuration', inherit => 0, extension => '.conf', default => sub {
  # Any lines starting with #, with or without leading whitespace, are treated as comments.
  # Comments are not parsed in option text; that is, you could specify an option that contained
  # a # and the # and following text would be considered part of that option.
  my ($data) = @_;
  my @options = grep /:\h+/o && ! /^\h*#/o && ! /^\h*$/o, split(/\v+/o, $data);
  s/^\h+//o for @options;
  my @key_values = map split(/\h*:\h+/o, $_, 2), @options;
  $key_values[$_ << 1] and $key_values[$_ << 1] =~ s/\s/_/go for 0 .. @key_values >> 1;
  $key_values[$_ << 1] and $key_values[$_ << 1] = lc $key_values[$_ << 1] for 0 .. @key_values >> 1;
  @key_values;
};

__
meta::meta('type::data', 'meta::functor::editable \'data\', extension => \'\', inherit => 0, default => \'cat\';');
meta::meta('type::function', <<'__');
meta::configure 'function', extension => '.pl', inherit => 1;
meta::define_form 'function', sub {
  my ($name, $value) = @_;
  meta::externalize $name, "function::$name", meta::eval_in("sub {\n$value\n}", "function::$name");
};
__
meta::meta('type::hook', <<'__');
meta::configure 'hook', extension => '.pl', inherit => 0;
meta::define_form 'hook', sub {
  my ($name, $value) = @_;
  *{"hook::$name"} = meta::eval_in("sub {\n$value\n}", "hook::$name");
};
__
meta::meta('type::inc', <<'__');
meta::configure 'inc', inherit => 1, extension => '.pl';
meta::define_form 'inc', sub {
  use File::Path 'mkpath';
  use File::Basename qw/basename dirname/;

  my ($name, $value) = @_;
  my $tmpdir   = basename($0) . '-' . $$;
  my $filename = "/tmp/$tmpdir/$name";

  push @INC, "/tmp/$tmpdir" unless grep /^\/tmp\/$tmpdir$/, @INC;

  mkpath(dirname($filename));
  unless (-e $filename) {
    open my $fh, '>', $filename;
    print $fh $value;
    close $fh;
  }
};
__
meta::meta('type::indicator', <<'__');
# Shell indicator function. The output of each of these is automatically
# appended to the shell prompt.

meta::configure 'indicator', inherit => 1, extension => '.pl';
meta::define_form 'indicator', sub {
  my ($name, $value) = @_;
  *{"indicator::$name"} = meta::eval_in("sub {\n$value\n}", "indicator::$name");
};
__
meta::meta('type::internal_function', <<'__');
meta::configure 'internal_function', extension => '.pl', inherit => 1;
meta::define_form 'internal_function', sub {
  my ($name, $value) = @_;
  *{$name} = meta::eval_in("sub {\n$value\n}", "internal_function::$name");
};
__
meta::meta('type::js', 'meta::functor::editable \'js\', extension => \'.js\', inherit => 1;');
meta::meta('type::library', <<'__');
meta::configure 'library', extension => '.pl', inherit => 1;
meta::define_form 'library', sub {
  my ($name, $value) = @_;
  meta::eval_in($value, "library::$name");
};
__
meta::meta('type::message_color', <<'__');
meta::configure 'message_color', extension => '', inherit => 1;
meta::define_form 'message_color', sub {
  my ($name, $value) = @_;
  terminal::color($name, $value);
};
__
meta::meta('type::meta', <<'__');
# This doesn't define a new type. It customizes the existing 'meta' type
# defined in bootstrap::initialization. Note that horrible things will
# happen if you redefine it using the editable functor.

meta::configure 'meta', extension => '.pl', inherit => 1;
__
meta::meta('type::note', 'meta::functor::editable \'note\', extension => \'.sdoc\', inherit => 0, default => \'edit\';');
meta::meta('type::parent', <<'__');
meta::define_form 'parent', \&meta::bootstrap::implementation;
meta::configure 'parent', extension => '', inherit => 1;
__
meta::meta('type::retriever', <<'__');
meta::configure 'retriever', extension => '.pl', inherit => 1;
meta::define_form 'retriever', sub {
  my ($name, $value) = @_;
  $transient{retrievers}{$name} = meta::eval_in("sub {\n$value\n}", "retriever::$name");
};
__
meta::meta('type::sdoc', <<'__');
# A meta-type for other types. So retrieve('js::main') will work if you have
# the attribute 'sdoc::js::main'. The filename will be main.js.sdoc.

meta::functor::editable 'sdoc', inherit => 1, extension => sub {
  extension_for(attribute($_[0])) . '.sdoc';
};
__
meta::meta('type::state', <<'__');
# Allows temporary or long-term storage of states. Nothing particularly insightful
# is done about compression, so storing alternative states will cause a large
# increase in size. Also, states don't contain other states -- otherwise the size
# increase would be exponential.

# States are created with the save-state function.

meta::configure 'state', inherit => 0, extension => '.pl';
meta::define_form 'state', \&meta::bootstrap::implementation;
__
meta::meta('type::template', <<'__');
meta::configure 'template', extension => '.pl', inherit => 1;
meta::define_form 'template', sub {
  my ($name, $value) = @_;
  meta::externalize "template::$name", "template::$name", meta::eval_in("sub {\n$value\n}", "template::$name");
};
__
meta::meta('type::todo', <<'__');
# Todo lists are special cases of SDoc syntax.
meta::configure 'todo', inherit => 0, extension => '.sdoc';
meta::define_form 'todo', sub {
  my ($name, $value) = @_;
  meta::externalize $name, "todo::$name", sub {
    return edit("todo::$name") if ! @_ || $_[0] eq 'edit';
    &{'todo-summary'}("todo::$name") if $_[0] eq 'show'}};

__
meta::meta('type::vim_highlighter', 'meta::functor::editable \'vim_highlighter\', extension => \'.vim\', inherit => 1, default => \'edit\';');
meta::alias('bs', 'todo-summary todo::bugs');
meta::alias('e', 'edit sdoc::js::kevlar');
meta::alias('ec', 'edit sdoc::js::kevlar.client.jquery');
meta::alias('edb', 'edit sdoc::js::kevlar.db');
meta::alias('es', 'edit sdoc::js::kevlar.server');
meta::alias('et', 'edit sdoc::js::kevlar.transport');
meta::alias('fs', 'features show');
meta::bootstrap('html', <<'__');
<html>
  <head>
  <meta http-equiv='content-type' content='text/html; charset=UTF-8' />
  <link rel='stylesheet' href='http://spencertipping.com/perl-objects/web/style.css'/>

  <script src='http://ajax.googleapis.com/ajax/libs/jquery/1.5.2/jquery.min.js'></script>
  <script src='http://spencertipping.com/caterwaul/caterwaul.all.min.js'></script>
  <script src='http://spencertipping.com/montenegro/montenegro.client.js'></script>
  <script src='http://spencertipping.com/perl-objects/web/attribute-parser.js'></script>
  <script src='http://spencertipping.com/perl-objects/web/interface.js'></script>
  </head>
  <body></body>
</html>

__
meta::bootstrap('initialization', <<'__');
#!/usr/bin/perl
# Run perldoc on this file for documentation.

# For the benefit of HTML viewers:
# <div id='cover' style='position: absolute; left: 0; top: 0; width: 10000px; height: 10000px; background: white'></div>

$|++;

my %data;
my %transient;
my %externalized_functions;
my %datatypes;

my %locations;          # Maps eval-numbers to attribute names

sub meta::define_form {
  my ($namespace, $delegate) = @_;
  $datatypes{$namespace} = $delegate;
  *{"meta::${namespace}::implementation"} = $delegate;
  *{"meta::$namespace"} = sub {
    my ($name, $value, %options) = @_;
    chomp $value;
    $data{"${namespace}::$name"} = $value unless $options{no_binding};
    &$delegate($name, $value) unless $options{no_delegate}}}

sub meta::eval_in {
  my ($what, $where) = @_;

  # Obtain next eval-number and alias it to the designated location
  @locations{eval('__FILE__') =~ /\(eval (\d+)\)/} = ($where);

  my $result = eval $what;
  $@ =~ s/\(eval \d+\)/$where/ if $@;
  warn $@ if $@;
  $result}

meta::define_form 'meta', sub {
  my ($name, $value) = @_;
  meta::eval_in($value, "meta::$name")};

__
meta::bootstrap('perldoc', <<'__');
=head1 Self-modifying Perl script

=head2 Original implementation by Spencer Tipping L<http://spencertipping.com>

The prototype for this script is licensed under the terms of the MIT source code license.
However, this script in particular may be under different licensing terms. To find out how
this script is licensed, please contact whoever sent it to you. Alternatively, you may
run it with the 'license' argument if they have specified a license that way.

You should not edit this file directly. For information about how it was constructed, go
to L<http://spencertipping.com/writing-self-modifying-perl>. For quick usage guidelines,
run this script with the 'usage' argument.

=cut

__
meta::cache('parent-identification', <<'__');
./sdoc 
/home/spencertipping/bin/configuration aa772900bb5b925cb84346bd72a4249d
/home/spencertipping/bin/node-base da62d84a9e81832f089520c172982c1a
/home/spencertipping/bin/object 99aeabc9ec7fe80b1b39f5e53dc7e49e
/home/spencertipping/bin/repository 05bc3036c343fdb8aec5b0be12a9b19e
/home/spencertipping/conjectures/perl-objects/sdoc a1e8480e579614c01dabeecf0f963bcc
notes a9e5975593ed5d90d943ad98405c71e5
object 99aeabc9ec7fe80b1b39f5e53dc7e49e
preprocessor 70dae4b46eb4e06798ec6f38d17d4c7b
todo 62bc8a83ef5d4941cd2c1cdfb57a0320
vim-highlighters 902333a0bd6ed90ff919fe8477cb4e69
__
meta::cached_dependency('caterwaul.js', <<'__');
// Core caterwaul build with version ID | Spencer Tipping
// Licensed under the terms of the MIT source code license



// Introduction.
// Caterwaul is a Javascript-to-Javascript compiler. Visit http://caterwauljs.org for information about how and why you might use it.

(function (f) {return f(f, (function (x) {return function () {return ++x}})(0))})(function (initializer, unique, undefined) {



// Utility methods.
// Gensym is used to support qs[]. When we quote syntax, what we really intend to do is grab a syntax tree representing something; this entails creating a let-binding with the already-evaluated
// tree. (Note: Don't go and modify these qs[]-generated trees; you only get one for each qs[].) The ultimate code ends up looking like this (see 'Environment-dependent compilation' some distance
// below):

// | (function (a_gensym) {
//     var v1 = a_gensym.gensym_1;
//     var v2 = a_gensym.gensym_2;
//     ...
//     return <your macroexpanded function>;
//   }) ({gensym_1: v1, gensym_2: v2, ..., gensym_n: vn});

// A note about gensym uniqueness. Gensyms are astronomically unlikely to collide, but there are some compromises made to make sure of this. First, gensyms are not predictable; the first one is
// randomized. This means that if you do have a collision, it may be intermittent (and that is probably a non-feature). Second, and this is a good thing, you can load Caterwaul multiple times
// without worrying about gensyms colliding between them. Each instance of Caterwaul uses its own system time and random number to seed the gensym generation, and the system time remains stable
// while the random number gets incremented. It is very unlikely that any collisions would happen.

// As of version 1.0 gensyms have an additional component to provide information about what they're being used for. This is used during gensym renaming; see the environment-dependent compilation
// source for more information about this.

// Bind() is the usual 'bind this function to some value' function. The only difference is that it supports rebinding; that is, if you have a function you've already bound to X, you can call bind
// on that function and some new value Y and get the original function bound to Y. The bound function has two attributes, 'original' and 'binding', that let bind() achieve this rebinding.

// Map() is an array map function, fairly standard really. I include it because IE doesn't provide Array.prototype.map. hash() takes a string, splits it on whitespace, and returns an object that
// maps each element to true. It's useful for defining sets. extend() takes a constructor function and zero or more extension objects, merging each extension object into the constructor
// function's prototype. The constructor function is then returned. It's a shorthand for defining classes.

// Se() stands for 'side-effect', and its purpose is to take a value and a function, pass the value into the function, and return either whatever the function returned or the value you gave it.
// It's used to initialize things statefully; for example:

// | return se(function () {return 5}, function (f) {
//     f.sourceCode = 'return 5';
//   });

    var qw = function (x) {return x.split(/\s+/)},  se = function (x, f) {return f && f.call(x, x) || x},  fail = function (m) {throw new Error(m)},
    genval = (function (n, m, u) {return function () {return [u, n, ++m]}})(+new Date(), Math.random() * (1 << 30) >>> 0, unique()),
    gensym = function (name) {var v = genval(); return ['gensym', name || '', v[0].toString(36), v[1].toString(36), v[2].toString(36)].join('_')},

   flatten = function () {for (var r = [], i = 0, l = arguments.length, x; i < l; ++i) (x = arguments[i]) instanceof Array ? r = r.concat(flatten.apply(this, x)) : r.push(x); return r},

       map = function (f, xs) {for (var i = 0, ys = [], l = xs.length; i < l; ++i) ys.push(f(xs[i], i)); return ys},
      rmap = function (f, xs) {return map(function (x) {return x instanceof Array ? rmap(f, x) : f(x)})},
      hash = function (s) {for (var i = 0, xs = qw(s), o = {}, l = xs.length; i < l; ++i) o[xs[i]] = true; return annotate_keys(o)},
     merge = function (o) {for (var i = 1, l = arguments.length, _; i < l; ++i) if (_ = arguments[i]) for (var k in _) has(_, k) && (o[k] = _[k]); return o},

//   Optimizations.
//   The parser and lexer each assume valid input and do no validation. This is possible because any function passed in to caterwaul will already have been parsed by the Javascript interpreter;
//   syntax errors would have caused an error there. This enables a bunch of optimization opportunities in the parser, ultimately making it not in any way recursive and requiring only three
//   linear-time passes over the token stream. (An approximate figure; it actually does about 19 fractional passes, but not all nodes are reached.)

//   Also, I'm not confident that all Javascript interpreters are smart about hash indexing. Particularly, suppose a hashtable has 10 entries, the longest of whose keys is 5 characters. If we
//   throw a 2K string at it, it might very well hash that whole thing just to find that, surprise, the entry doesn't exist. That's a big performance hit if it happens very often. To prevent this
//   kind of thing, I'm keeping track of the longest string in the hashtable by using the 'annotate_keys' function. 'has()' knows how to look up the maximum length of a hashtable to verify that
//   the candidate is in it, resulting in the key lookup being only O(n) in the longest key (generally this ends up being nearly O(1), since I don't like to type long keys), and average-case O(1)
//   regardless of the length of the candidate.

//   As of Caterwaul 0.7.0 the _max_length property has been replaced by a gensym. This basically guarantees uniqueness, so the various hacks associated with working around the existence of the
//   special _max_length key are no longer necessary.

   max_length_key = gensym('hash_annotation'),
    annotate_keys = function (o)    {var max = 0; for (var k in o) own.call(o, k) && (max = k.length > max ? k.length : max); o[max_length_key] = max; return o},
              has = function (o, p) {return p != null && ! (p.length > o[max_length_key]) && own.call(o, p)},  own = Object.prototype.hasOwnProperty;
// Generated by SDoc 





// Global caterwaul variable.
// Caterwaul creates a global symbol, caterwaul. Like jQuery, there's a mechanism to get the original one back if you don't want to replace it. You can call caterwaul.deglobalize() to return
// caterwaul and restore the global that was there when Caterwaul was loaded (might be useful in the unlikely event that someone else named their library Caterwaul). Note that deglobalize() is
// available only on the global caterwaul() function.

  var calls_init       = function () {var f = function () {return f.init.apply(f, arguments)}; return f},
      original_global  = typeof caterwaul === 'undefined' ? undefined : caterwaul,
      caterwaul_global = calls_init();

  caterwaul_global.deglobalize = function () {caterwaul = original_global; return caterwaul_global};

//   Version management and reinitialization.
//   There's an interesting case that comes up when loading a global caterwaul. If we detect that the caterwaul we just loaded has the same version as the one that's already there, we revert back
//   to the original. This is very important for precompilation and the reason for it is subtle. Precompilation relies on tracing to determine the compiled form of each function handed to
//   caterwaul, so if that caterwaul is replaced for any reason then the traces won't happen.

//   There is, of course, a pathological failure case in all of this. If you load three caterwauls [why?] and the second of the three has a different version than the other two, then you'll still
//   get precompiled erasure. I personally don't care about this case. You'd have to be insane to do crazy stuff like this and expect precompilation to work.

    caterwaul_global.version      = function (v) {return v ? (this._version = v, original_global && original_global.version() === v ? this.deglobalize() : this) : this._version};
    caterwaul_global.reinitialize = function (transform) {var c = (transform || function (x) {return x})(this.initializer);
                                                          return c(c, this.unique).version(this.version())};

//   Utility methods.
//   These are available for use by compiler functions or the end user.

    merge(caterwaul_global, {
      merge:          merge,
      map:            map,
      rmap:           rmap,
      flatten:        flatten,
      gensym:         gensym,
      unique:         unique,
      initializer:    initializer,

      variadic:       function (f) {return function () {for (var r = [], i = 0, l = arguments.length;                       i < l; ++i) r.push(f.call(this, arguments[i]));    return r}},
      right_variadic: function (f) {return function () {for (var r = [], i = 0, l = arguments.length - 1, x = arguments[l]; i < l; ++i) r.push(f.call(this, arguments[i], x)); return r}}});
// Generated by SDoc 






// Shared parser data.
// This data is used both for parsing and for serialization, so it's made available to all pieces of caterwaul.

//   Precomputed table values.
//   The lexer uses several character lookups, which I've optimized by using integer->boolean arrays. The idea is that instead of using string membership checking or a hash lookup, we use the
//   character codes and index into a numerical array. This is guaranteed to be O(1) for any sensible implementation, and is probably the fastest JS way we can do this. For space efficiency,
//   only the low 256 characters are indexed. High characters will trigger sparse arrays, which may degrade performance. Also, this parser doesn't handle Unicode characters properly; it assumes
//   lower ASCII only.

//   The lex_op table indicates which elements trigger regular expression mode. Elements that trigger this mode cause a following / to delimit a regular expression, whereas other elements would
//   cause a following / to indicate division. By the way, the operator ! must be in the table even though it is never used. The reason is that it is a substring of !==; without it, !== would
//   fail to parse.

   var lex_op = hash('. new ++ -- u++ u-- u+ u- typeof u~ u! ! * / % + - << >> >>> < > <= >= instanceof in == != === !== & ^ | && || ? = += -= *= /= %= &= |= ^= <<= >>= >>>= : , ' +
                     'return throw case var const break continue void else u; ;'),

    lex_table = function (s) {for (var i = 0, xs = [false]; i < 8; ++i) xs.push.apply(xs, xs); for (var i = 0, l = s.length; i < l; ++i) xs[s.charCodeAt(i)] = true; return xs},
    lex_float = lex_table('.0123456789'),    lex_decimal = lex_table('0123456789'),  lex_integer = lex_table('0123456789abcdefABCDEFx'),  lex_exp = lex_table('eE'),
    lex_space = lex_table(' \n\r\t'),        lex_bracket = lex_table('()[]{}'),       lex_opener = lex_table('([{'),                    lex_punct = lex_table('+-*/%&|^!~=<>?:;.,'),
      lex_eol = lex_table('\n\r'),     lex_regexp_suffix = lex_table('gims'),          lex_quote = lex_table('\'"/'),                   lex_slash = '/'.charCodeAt(0),
     lex_star = '*'.charCodeAt(0),              lex_back = '\\'.charCodeAt(0),             lex_x = 'x'.charCodeAt(0),                     lex_dot = '.'.charCodeAt(0),
     lex_zero = '0'.charCodeAt(0),     lex_postfix_unary = hash('++ --'),              lex_ident = lex_table('$_abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'),

//   Parse data.
//   The lexer and parser aren't entirely separate, nor can they be considering the complexity of Javascript's grammar. The lexer ends up grouping parens and identifying block constructs such
//   as 'if', 'for', 'while', and 'with'. The parser then folds operators and ends by folding these block-level constructs.

    parse_reduce_order = map(hash, ['function', '( [ . [] ()', 'new delete', 'u++ u-- ++ -- typeof u~ u! u+ u-', '* / %', '+ -', '<< >> >>>', '< > <= >= instanceof in', '== != === !==', '&',
                                    '^', '|', '&&', '||', 'case', '?', '= += -= *= /= %= &= |= ^= <<= >>= >>>=', ':', ',', 'return throw break continue void', 'var const',
                                    'if else try catch finally for switch with while do', ';']),

parse_associates_right = hash('= += -= *= /= %= &= ^= |= <<= >>= >>>= ~ ! new typeof u+ u- -- ++ u-- u++ ? if else function try catch finally for switch case with while do'),
   parse_inverse_order = (function (xs) {for (var  o = {}, i = 0, l = xs.length; i < l; ++i) for (var k in xs[i]) has(xs[i], k) && (o[k] = i); return annotate_keys(o)})(parse_reduce_order),
   parse_index_forward = (function (rs) {for (var xs = [], i = 0, l = rs.length, _ = null; _ = rs[i], xs[i] = true, i < l; ++i)
                                           for (var k in _) if (has(_, k) && (xs[i] = xs[i] && ! has(parse_associates_right, k))) break; return xs})(parse_reduce_order),

              parse_lr = hash('[] . () * / % + - << >> >>> < > <= >= instanceof in == != === !== & ^ | && || = += -= *= /= %= &= |= ^= <<= >>= >>>= , : ;'),
   parse_r_until_block = annotate_keys({'function':2, 'if':1, 'do':1, 'catch':1, 'try':1, 'for':1, 'while':1, 'with':1, 'switch':1}),
         parse_accepts = annotate_keys({'if':'else', 'do':'while', 'catch':'finally', 'try':'catch'}),  parse_invocation = hash('[] ()'),
      parse_r_optional = hash('return throw break continue else'),              parse_r = hash('u+ u- u! u~ u++ u-- new typeof finally case var const void delete'),
           parse_block = hash('; {'),  parse_invisible = hash('i;'),            parse_l = hash('++ --'),     parse_group = annotate_keys({'(':')', '[':']', '{':'}', '?':':'}),
 parse_ambiguous_group = hash('[ ('),    parse_ternary = hash('?'),   parse_not_a_value = hash('function if for while catch void delete new typeof in instanceof'),
 parse_also_expression = hash('function');
// Generated by SDoc 





// Syntax data structures.
// There are two data structures used for syntax trees. At first, paren-groups are linked into doubly-linked lists, described below. These are then folded into immutable array-based specific
// nodes. At the end of folding there is only one child per paren-group.

//   Doubly-linked paren-group lists.
//   When the token stream is grouped into paren groups it has a hierarchical linked structure that conceptually has these pointers:

//   |                       +--------+
//                  +------  |  node  |  ------+
//                  |   +->  |        |  <--+  |
//           first  |   |    +--------+     |  |  last
//                  |   | parent     parent |  |
//                  V   |                   |  V
//               +--------+               +--------+
//               |  node  |   --- r -->   |  node  |  --- r ---/
//    /--- l --- |        |   <-- l ---   |        |
//               +--------+               +--------+

//   The primary operation performed on this tree, at least initially, is repeated folding. So we have a chain of linear nodes, and one by one certain nodes fold their siblings underneath them,
//   breaking the children's links and linking instead to the siblings' neighbors. For example, if we fold node (3) as a binary operator:

//   |     (1) <-> (2) <-> (3) <-> (4) <-> (5)             (1) <--> (3) <--> (5)
//         / \     / \     / \     / \     / \     -->     / \     /   \     / \
//                                                                /     \
//                                                              (2)     (4)        <- No link between children
//                                                              / \     / \           (see 'Fold nodes', below)

//   Fold nodes.
//   Once a node has been folded (e.g. (3) in the diagram above), none of its children will change and it will gain no more children. The fact that none of its children will change can be shown
//   inductively: suppose you've decided to fold the '+' in 'x + y' (here x and y are arbitrary expressions). This means that x and y are comprised of higher-precedence operators. Since there is
//   no second pass back to high-precedence operators, x and y will not change nor will they interact with one another. The fact that a folded node never gains more children arrives from the fact
//   that it is folded only once; this is by virtue of folding by index instead of by tree structure. (Though a good tree traversal algorithm also wouldn't hit the same node twice -- it's just
//   less obvious when the tree is changing.)

//   Anyway, the important thing about fold nodes is that their children don't change. This means that an array is a completely reasonable data structure to use for the children; it certainly
//   makes the structure simpler. It also means that the only new links that must be added to nodes as they are folded are links to new children (via the array), and links to the new siblings.
//   Once we have the array-form of fold nodes, we can build a query interface similar to jQuery, but designed for syntactic traversal. This will make routine operations such as macro
//   transformation and quasiquoting far simpler later on.

//   Both grouping and fold nodes are represented by the same data structure. In the case of grouping, the 'first' pointer is encoded as [0] -- that is, the first array element. It doesn't
//   contain pointers to siblings of [0]; these are still accessed by their 'l' and 'r' pointers. As the structure is folded, the number of children of each paren group should be reduced to just
//   one. At this point the remaining element's 'l' and 'r' pointers will both be null, which means that it is in hierarchical form instead of linked form.

//   After the tree has been fully generated and we have the root node, we have no further use for the parent pointers. This means that we can use subtree sharing to save memory. Once we're past
//   the fold stage, push() should be used instead of append(). append() works in a bidirectionally-linked tree context (much like the HTML DOM), whereas push() works like it does for arrays
//   (i.e. no parent pointer).

//   Syntax node functions.
//   These functions are common to various pieces of syntax nodes. Not all of them will always make sense, but the prototypes of the constructors can be modified independently later on if it
//   turns out to be an issue.

    var syntax_common = caterwaul_global.syntax_common = {

//     Mutability.
//     These functions let you modify nodes in-place. They're used during syntax folding and shouldn't really be used after that (hence the underscores).

      _replace:  function (n) {return (n.l = this.l) && (this.l.r = n), (n.r = this.r) && (this.r.l = n), this},  _append_to: function (n) {return n && n._append(this), this},
      _reparent: function (n) {return this.p && this.p[0] === this && (this.p[0] = n), this},  _fold_l: function (n) {return this._append(this.l && this.l._unlink(this) || empty)},
      _append:   function (n) {return (this[this.length++] = n) && (n.p = this), this},        _fold_r: function (n) {return this._append(this.r && this.r._unlink(this) || empty)},
      _sibling:  function (n) {return n.p = this.p, (this.r = n).l = this},                    _fold_lr: function () {return this._fold_l()._fold_r()},
                                                                                               _fold_rr: function () {return this._fold_r()._fold_r()},

      _wrap:     function (n) {return n.p = this._replace(n).p, this._reparent(n), delete this.l, delete this.r, this._append_to(n)},
      _unlink:   function (n) {return this.l && (this.l.r = this.r), this.r && (this.r.l = this.l), delete this.l, delete this.r, this._reparent(n)},

//     These methods are OK for use after the syntax folding stage is over (though because syntax nodes are shared it's generally dangerous to go modifying them):

      pop: function () {return --this.length, this},  push: function (x) {return this[this.length++] = x || empty, this},

//     Identification.
//     You can request that a syntax node identify itself, in which case it will give you an identifier if it hasn't already. The identity is not determined until the first time it is requested,
//     and after that it is stable. As of Caterwaul 0.7.0 the mechanism works differently (i.e. isn't borked) in that it replaces the prototype definition with an instance-specific closure the
//     first time it gets called. This may reduce the number of decisions in the case that the node's ID has already been computed.

      id: function () {var id = gensym('id'); return (this.id = function () {return id})()},

//     Traversal functions.
//     each() is the usual side-effecting shallow traversal that returns 'this'. map() distributes a function over a node's children and returns the array of results, also as usual. Two variants,
//     reach and rmap, perform the process recursively. reach is non-consing; it returns the original as a reference. rmap, on the other hand, follows some rules to cons a new tree. If the
//     function passed to rmap() returns the node verbatim then its children are traversed. If it returns a distinct node, however, then traversal doesn't descend into the children of the newly
//     returned tree but rather continues as if the original node had been a leaf. For example:

//     |           parent          Let's suppose that a function f() has these mappings:
//                /      \
//            node1      node2       f(parent) = parent   f(node1) = q
//            /   \        |                              f(node2) = node2
//          c1     c2      c3

//     In this example, f() would be called on parent, node1, node2, and c3 in that order. c1 and c2 are omitted because node1 was replaced by q -- and there is hardly any point in going through
//     the replaced node's previous children. (Nor is there much point in forcibly iterating over the new node's children, since presumably they are already processed.) If a mapping function
//     returns something falsy, it will have exactly the same effect as returning the node without modification.

//     Using the old s() to do gensym-safe replacement requires that you invoke it only once, and this means that for complex macroexpansion you'll have a long array of values. This isn't ideal,
//     so syntax trees provide a replace() function that handles replacement more gracefully:

//     | qs[(foo(_foo), _before_bar + bar(_bar))].replace({_foo: qs[x], _before_bar: qs[3 + 5], _bar: qs[foo.bar]})

      each:  function (f) {for (var i = 0, l = this.length; i < l; ++i) f(this[i], i); return this},
      map:   function (f) {for (var n = new this.constructor(this), i = 0, l = this.length; i < l; ++i) n.push(f(this[i], i) || this[i]); return n},

      reach: function (f) {f(this); this.each(function (n) {n.reach(f)}); return this},
      rmap:  function (f) {var r = f(this); return ! r || r === this ? this.map(function (n) {return n.rmap(f)}) : r.rmap === undefined ? new this.constructor(r) : r},

      clone: function () {return this.rmap(function () {return false})},

      collect: function (p)  {var ns = []; this.reach(function (n) {p(n) && ns.push(n)}); return ns},
      replace: function (rs) {var r; return own.call(rs, this.data) && (r = rs[this.data]) ?
                                              r.constructor === String ? se(this.map(function (n) {return n.replace(rs)}), function () {this.data = r}) : r :
                                              this.map(function (n) {return n.replace(rs)})},

//     Alteration.
//     These functions let you make "changes" to a node by returning a modified copy.

      repopulated_with: function (xs)   {return new this.constructor(this.data, xs)},
      change:           function (i, x) {return se(new this.constructor(this.data, Array.prototype.slice.call(this)), function (n) {n[i] = x})},
      compose_single:   function (i, f) {return this.change(i, f(this[i]))},

//     General-purpose traversal.
//     This is a SAX-style traversal model, useful for analytical or scope-oriented tree traversal. You specify a callback function that is invoked in pre-post-order on the tree (you get events
//     for entering and exiting each node, including leaves). Each time a node is entered, the callback is invoked with an object of the form {entering: node}, where 'node' is the syntax node
//     being entered. Each time a node is left, the callback is invoked with an object of the form {exiting: node}. The return value of the function is not used. Any null nodes are not traversed,
//     since they would fail any standard truthiness tests for 'entering' or 'exiting'.

//     I used to have a method to perform scope-annotated traversal, but I removed it for two reasons. First, I had no use for it (and no tests, so I had no reason to believe that it worked).
//     Second, Caterwaul is too low-level to need such a method. That would be more appropriate for an analysis extension.

      traverse: function (f) {f({entering: this}); f({exiting: this.each(function (n) {n.traverse(f)})}); return this},

//     Structural transformation.
//     Having nested syntax trees can be troublesome. For example, suppose you're writing a macro that needs a comma-separated list of terms. It's a lot of work to dig through the comma nodes,
//     each of which is binary. Javascript is better suited to using a single comma node with an arbitrary number of children. (This also helps with the syntax tree API -- we can use .map() and
//     .each() much more effectively.) Any binary operator can be transformed this way, and that is exactly what the flatten() method does. (flatten() returns a new tree; it doesn't modify the
//     original.)

//     The tree flattening operation looks like this for a left-associative binary operator:

//     |        (+)
//             /   \              (+)
//          (+)     z     ->     / | \
//         /   \                x  y  z
//        x     y

//     This flatten() method returns the nodes along the chain of associativity, always from left to right. It is shallow, since generally you only need a localized flat tree. That is, it doesn't
//     descend into the nodes beyond the one specified by the flatten() call. It takes an optional parameter indicating the operator to flatten over; if the operator in the tree differs, then the
//     original node is wrapped in a unary node of the specified operator. The transformation looks like this:

//     |                                  (,)
//            (+)                          |
//           /   \   .flatten(',')  ->    (+)
//          x     y                      /   \
//                                      x     y

//     Because ',' is a binary operator, a ',' tree with just one operand will be serialized exactly as its lone operand would be. This means that plurality over a binary operator such as comma
//     or semicolon degrades gracefully for the unary case (this sentence makes more sense in the context of macro definitions; see in particular 'let' and 'where' in std.bind).

//     The unflatten() method performs the inverse transformation. It doesn't delete a converted unary operator in the tree case, but if called on a node with more than two children it will nest
//     according to associativity.

      flatten:   function (d) {d = d || this.data; return d !== this.data ? this.as(d) : ! (has(parse_lr, d) && this.length) ? this : has(parse_associates_right, d) ?
                                                     se(new this.constructor(d), bind(function (n) {for (var i = this;     i && i.data === d; i = i[1]) n.push(i[0]); n.push(i)}, this)) :
                                                     se(new this.constructor(d), bind(function (n) {for (var i = this, ns = []; i.data === d; i = i[0]) i[1] && ns.push(i[1]); ns.push(i);
                                                                                                    for (i = ns.length - 1; i >= 0; --i) n.push(ns[i])}, this))},

      unflatten: function  () {var t = this, right = has(parse_associates_right, this.data); return this.length <= 2 ? this : se(new this.constructor(this.data), function (n) {
                                 if (right) for (var i = 0, l = t.length - 1; i  < l; ++i) n = n.push(t[i]).push(i < l - 2 ? new t.constructor(t.data) : t[i])[1];
                                 else       for (var i = t.length - 1;        i >= 1; --i) n = n.push(i > 1 ? new t.constructor(t.data) : t[0]).push(t[i])[0]})},

//     Wrapping.
//     Sometimes you want your syntax tree to have a particular operator, and if it doesn't have that operator you want to wrap it in a node that does. Perhaps the most common case of this is
//     when you have a possibly-plural node representing a variable or expression -- often the case when you're dealing with argument lists -- and you want to be able to assume that it's wrapped
//     in a comma node. Calling node.as(',') will return the node if it's a comma, and will return a new comma node containing the original one if it isn't.

      as: function (d) {return this.data === d ? this : new this.constructor(d).push(this)},

//     Type detection and retrieval.
//     These methods are used to detect the literal type of a node and to extract that value if it exists. You should use the as_x methods only once you know that the node does represent an x;
//     otherwise you will get misleading results. (For example, calling as_boolean on a non-boolean will always return false.)

//     Other methods are provided to tell you higher-level things about what this node does. For example, is_contextualized_invocation() tells you whether the node represents a call that can't be
//     eta-reduced (if it were, then the 'this' binding would be lost).

//     Wildcards are used for pattern matching and are identified by beginning with an underscore. This is a very frequently-called method, so I'm using a very inexpensive numeric check rather
//     than a string comparison. The ASCII value for underscore is 95.

               is_string: function () {return /['"]/.test(this.data.charAt(0))},           as_escaped_string: function () {return this.data.substr(1, this.data.length - 2)}, 
               is_number: function () {return /^-?(0x|\d|\.\d+)/.test(this.data)},                 as_number: function () {return Number(this.data)},
              is_boolean: function () {return this.data === 'true' || this.data === 'false'},     as_boolean: function () {return this.data === 'true'},
               is_regexp: function () {return /^\/./.test(this.data)},                     as_escaped_regexp: function () {return this.data.substring(1, this.data.lastIndexOf('/'))},

             is_wildcard: function () {return this.data.charCodeAt(0) === 95},

       has_grouped_block: function () {return has(parse_r_until_block, this.data)},                 is_block: function () {return has(parse_block, this.data)},
    is_blockless_keyword: function () {return has(parse_r_optional, this.data)},        is_null_or_undefined: function () {return this.data === 'null' || this.data === 'undefined'},

             is_constant: function () {return this.is_number() || this.is_string() || this.is_boolean() || this.is_regexp() || this.is_null_or_undefined()},
          left_is_lvalue: function () {return /=$/.test(this.data) || /\+\+$/.test(this.data) || /--$/.test(this.data)},
                is_empty: function () {return !this.length},                              has_parameter_list: function () {return this.data === 'function' || this.data === 'catch'},
         has_lvalue_list: function () {return this.data === 'var' || this.data === 'const'},  is_dereference: function () {return this.data === '.' || this.data === '[]'},
           is_invocation: function () {return this.data === '()'},              is_contextualized_invocation: function () {return this.is_invocation() && this[0].is_dereference()},

            is_invisible: function () {return has(parse_invisible, this.data)},           is_binary_operator: function () {return has(parse_lr, this.data)},
is_prefix_unary_operator: function () {return has(parse_r, this.data)},            is_postfix_unary_operator: function () {return has(parse_l,  this.data)},
       is_unary_operator: function () {return this.is_prefix_unary_operator() || this.is_postfix_unary_operator()},

                 accepts: function (e) {return has(parse_accepts, this.data) && parse_accepts[this.data] === (e.data || e)},

//     Value construction.
//     Syntax nodes sometimes represent hard references to values instead of just syntax. (See 'References' for more information.) In order to compile a syntax tree in the right environment you
//     need a mapping of symbols to these references, which is what the bindings() method returns. (It also collects references for all descendant nodes.) It takes an optional argument to
//     populate, in case you already had a hash set aside for bindings -- though it always returns the hash.

//     A bug in Caterwaul 0.5 and earlier failed to bind falsy values. This is no longer the case; nodes which bind values should indicate that they do so by setting a binds_a_value attribute
//     (ref nodes do this on the prototype), indicating that their value should be read from the 'value' property. (This allows other uses of a 'value' property while making it unambiguous
//     whether a particular node intends to bind something.)

      bindings: function (hash) {var result = hash || {}; this.reach(function (n) {if (n.binds_a_value) result[n.data] = n.value}); return result},

//     Matching.
//     Any syntax tree can act as a matching pattern to destructure another one. It's often much more fun to do things this way than it is to try to pick it apart by hand. For example, suppose
//     you wanted to determine whether a node represents a function that immediately returns, and to know what it returns. The simplest way to do it is like this:

//     | var tree = ...
//       var match = caterwaul.parse('function (_) {return _value}').match(tree);
//       if (match) {
//         var value = match._value;
//         ...
//       }

//     The second parameter 'variables' stores a running total of match data. You don't provide this; match() creates it for you on the toplevel invocation. The entire original tree is available
//     as a match variable called '_'; for example: t.match(u)._ === u if u matches t.

      match: function (target, variables) {target = caterwaul_global.ensure_syntax(target);
                                           variables || (variables = {_: target});
                                           if (this.is_wildcard())                                          return variables[this.data] = target, variables;
                                      else if (this.length === target.length && this.data === target.data) {for (var i = 0, l = this.length; i < l; ++i)
                                                                                                              if (! this[i].match(target[i], variables)) return null;
                                                                                                            return variables}},

//     Inspection and syntactic serialization.
//     Syntax nodes can be both inspected (producing a Lisp-like structural representation) and serialized (producing valid Javascript code). Each representation captures stray links via the 'r'
//     pointer. In the serialized representation, it is shown as a comment /* -> */ containing the serialization of whatever is to the right. This has the property that it will break tests but
//     won't necessarily break code (though if it happens in the field then it's certainly a bug).

//     Block detection is required for multi-level if/else statements. Consider this code:

//     | if (foo) for (...) {}
//       else bif;

//     A naive approach (the one I was using before version 0.6) would miss the fact that the 'for' was trailed by a block, and insert a spurious semicolon, which would break compilation:

//     | if (foo) for (...) {};    // <- note!
//       else bif;

//     What we do instead is dig through the tree and find out whether the last thing in the 'if' case ends with a block. If so, then no semicolon is inserted; otherwise we insert one. This
//     algorithm makes serialization technically O(n^2), but nobody nests if/else blocks to such an extent that it would matter.

      ends_with_block: function () {var block = this[parse_r_until_block[this.data]];
                                    return this.data === '{' || has(parse_r_until_block, this.data) && (this.data !== 'function' || this.length === 3) && block && block.ends_with_block()},

//     There's a hack here for single-statement if-else statements. (See 'Grab-until-block behavior' in the parsing code below.) Basically, for various reasons the syntax tree won't munch the
//     semicolon and connect it to the expression, so we insert one automatically whenever the second node in an if, else, while, etc. isn't a block.

//     Update for Caterwaul 0.6.6: I had removed mandatory spacing for unary prefix operators, but now it's back. The reason is to help out the host Javascript lexer, which can misinterpret
//     postfix increment/decrement: x + +y will be serialized as x++y, which is invalid Javascript. The fix is to introduce a space in front of the second plus: x+ +y, which is unambiguous.

//     Update for caterwaul 1.0: The serialize() method is now aggressively optimized for common cases. It also uses a flattened array-based concatenation strategy rather than the deeply nested
//     approach from before.

//     Optimized serialization cases.
//     We can tell a lot about how to serialize a node based on just a few properties. For example, if the node has zero length then its serialization is simply its data. This is the leaf case,
//     which is likely to be half of the total number of nodes in the whole syntax tree. If a node has length 1, then we assume a prefix operator unless we identify it as postfix. Otherwise we
//     break it down by the kind of operator that it is.

//     Nodes might be flattened, so we can't assume any upper bound on the arity regardless of what kind of operator it is. Realistically you shouldn't hand flattened nodes over to the compile()
//     function, but it isn't the end of the world if you do.

      structure: function () {if (this.length) return '(' + ['"' + this.data + '"'].concat(map(function (x) {return x.structure()}, this)).join(' ') + ')';
                              else             return this.data},

      toString:  function ()   {var xs = ['']; this.serialize(xs); return xs.join('')},
      serialize: function (xs) {var l = this.length, d = this.data, semi = ';\n',
                                 push = function (x) {if (lex_ident[xs[xs.length - 1].charCodeAt(0)] === lex_ident[x.charCodeAt(0)]) xs.push(' ', x);
                                                      else                                                                           xs.push(x)};

                                switch (l) {case 0: if (has(parse_r_optional, d)) return push(d.replace(/^u/, ''));
                                               else if (has(parse_group, d))      return push(d), push(parse_group[d]);
                                               else                               return push(d);

                                            case 1: if (has(parse_r, d) || has(parse_r_optional, d)) return push(d.replace(/^u/, '')), this[0].serialize(xs);
                                               else if (has(parse_group, d))                         return push(d), this[0].serialize(xs), push(parse_group[d]);
                                               else if (has(parse_lr, d))                            return push('/* unary ' + d + ' node */'), this[0].serialize(xs);
                                               else                                                  return this[0].serialize(xs), push(d);

                                            case 2: if (has(parse_invocation, d))    return this[0].serialize(xs), push(d.charAt(0)), this[1].serialize(xs), push(d.charAt(1));
                                               else if (has(parse_r_until_block, d)) return push(d), this[0].serialize(xs), this[1].serialize(xs);
                                               else if (has(parse_invisible, d))     return this[0].serialize(xs), this[1].serialize(xs);
                                               else if (d === ';')                   return this[0].serialize(xs), push(semi), this[1].serialize(xs);
                                               else                                  return this[0].serialize(xs), push(d), this[1].serialize(xs);

                                           default: if (has(parse_ternary, d))       return this[0].serialize(xs), push(d), this[1].serialize(xs), push(':'), this[2].serialize(xs);
                                               else if (has(parse_r_until_block, d)) return this.accepts(this[2]) && ! this[1].ends_with_block() ?
                                                                                       (push(d), this[0].serialize(xs), this[1].serialize(xs), push(semi), this[2].serialize(xs)) :
                                                                                       (push(d), this[0].serialize(xs), this[1].serialize(xs), this[2].serialize(xs));
                                               else                                  return this.unflatten().serialize(xs)}}};


//   References.
//   You can drop references into code that you're compiling. This is basically variable closure, but a bit more fun. For example:

//   | caterwaul.compile(qs[fn_[_ + 1]].replace({_: caterwaul.ref(3)}))()    // -> 4

//   What actually happens is that caterwaul.compile runs through the code replacing refs with gensyms, and the function is evaluated in a scope where those gensyms are bound to the values they
//   represent. This gives you the ability to use a ref even as an lvalue, since it's really just a variable. References are always leaves on the syntax tree, so the prototype has a length of 0.

//   Caterwaul 1.0 adds named gensyms, and one of the things you can do is name your refs accordingly. If you don't name one it will just be called 'ref', but you can make it more descriptive by
//   passing in a second constructor argument. This name will automatically be wrapped in a gensym, but that gensym will be removed at compile-time unless you specify not to rename gensyms.

    caterwaul_global.ref = function (value, name) {if (value instanceof this.constructor) this.value = value.value, this.data = value.data;
                                                   else                                   this.value = value,       this.data = gensym(name && name.constructor === String ? name : 'ref')};

    merge(caterwaul_global.ref.prototype, syntax_common, {binds_a_value: true, length: 0});

//   Reference replace() support.
//   Refs aren't normal nodes; in particular, invoking the constructor as we do in replace() will lose the ref's value and cause all kinds of problems. In order to avoid this we override the
//   replace() method for syntax refs to behave more sensibly. Note that you can't replace a ref with a syntax 

    caterwaul_global.ref.prototype.replace = function (replacements) {var r; return own.call(replacements, this.data) && (r = replacements[this.data]) ?
                                                                                      r.constructor === String ? se(new this.constructor(this.value), function () {this.data = r}) : r :
                                                                                      this};

//   Syntax node constructor.
//   Here's where we combine all of the pieces above into a single function with a large prototype. Note that the 'data' property is converted from a variety of types; so far we support strings,
//   numbers, and booleans. Any of these can be added as children. Also, I'm using an instanceof check rather than (.constructor ===) to allow array subclasses such as Caterwaul finite sequences
//   to be used.

    caterwaul_global.syntax = function (data) {if (data instanceof this.constructor) this.data = data.data, this.length = 0;
                                               else {this.data = data && data.toString(); this.length = 0;
                                                 for (var i = 1, l = arguments.length, _; _ = arguments[i], i < l; ++i)
                                                   for (var j = 0, lj = _.length, it, c; _ instanceof Array ? (it = _[j], j < lj) : (it = _, ! j); ++j)
                                                     this._append((c = it.constructor) === String || c === Number || c === Boolean ? new this.constructor(it) : it)}};

    merge(caterwaul_global.syntax.prototype, syntax_common);

    var empty = caterwaul_global.empty = new caterwaul_global.syntax('');
// Generated by SDoc 





// Parsing.
// There are two distinct parts to parsing Javascript. One is parsing the irregular statement-mode expressions such as 'if (condition) {...}' and 'function f(x) {...}'; the other is parsing
// expression-mode stuff like arithmetic operators. In Rebase I tried to model everything as an expression, but that failed sometimes because it required that each operator have fixed arity. In
// particular this was infeasible for keywords such as 'break', 'continue', 'return', and some others (any of these can be nullary or unary). It also involved creating a bizarre hack for 'case
// x:' inside a switch block. This hack made the expression passed in to 'case' unavailable, as it would be buried in a ':' node.

// Caterwaul fixes these problems by using a proper context-free grammar. However, it's much looser than most grammars because it doesn't need to validate anything. Correspondingly, it can be
// much faster as well. Instead of guessing and backtracking as a recursive-descent parser would, it classifies many different branches into the same basic structure and fills in the blanks. One
// example of this is the () {} pair, which occurs in a bunch of different constructs, including function () {}, if () {}, for () {}, etc. In fact, any time a () group is followed by a {} group
// we can grab the token that precedes () (along with perhaps one more in the case of function f () {}), and group that under whichever keyword is responsible.

//   Syntax folding.
//   The first thing to happen is that parenthetical, square bracket, and braced groups are folded up. This happens in a single pass that is linear in the number of tokens, and other foldable
//   tokens (including unary and binary operators) are indexed by associativity. The following pass runs through these indexes from high to low precedence and folds tokens into trees. By this
//   point all of the parentheticals have been replaced by proper nodes (here I include ?: groups in parentheticals, since they behave the same way). Finally, high-level rules are applied to the
//   remaining keywords, which are bound last. This forms a complete parse tree.

//   Doing all of this efficiently requires a linked list rather than an array. This gets built during the initial paren grouping stage. Arrays are used for the indexes, which are left-to-right
//   and are later processed in the order indicated by the operator associativity. That is, left-associative operators are processed 0 .. n and right associative are processed n .. 0. Keywords
//   are categorized by behavior and folded after all of the other operators. Semicolons are folded last, from left to right.

//   There are some corner cases due to Javascript's questionable heritage from C-style syntax. For example, most constructs take either syntax blocks or semicolon-delimited statements. Ideally,
//   else, while, and catch are associated with their containing if, do, and try blocks, respectively. This can be done easily, as the syntax is folded right-to-left. Another corner case would
//   come up if there were any binary operators with equal precedence and different associativity. Javascript doesn't have them however, and it wouldn't make much sense to; it would render
//   expressions such as 'a op1 b op2 c' ambiguous if op1 and op2 shared precedence but each wanted to bind first. (I mention this because at first I was worried about it, but now I realize it
//   isn't an issue.)

//   Notationally (for easier processing later on), a distinction is made between invocation and grouping, and between dereferencing and array literals. Dereferencing and function invocation are
//   placed into their own operators, where the left-hand side is the thing being invoked or dereferenced and the right-hand side is the paren-group or bracket-group that is responsible for the
//   operation. Also, commas inside these groups are flattened into a single variadic (possibly nullary) comma node so that you don't have to worry about the tree structure. This is the case for
//   all left-associative operators; right-associative operators preserve their hierarchical folding.

//   Parse/lex shared logic.
//   Lexing Javascript is not entirely straightforward, primarily because of regular expression literals. The first implementation of the lexer got things right 99% of the time by inferring the
//   role of a / by its preceding token. The problem comes in when you have a case like this:

//   | if (condition) /foo/.test(x)

//   In this case, (condition) will be incorrectly inferred to be a regular expression (since the close-paren terminates an expression, usually), and /foo/ will be interpreted as division by foo. 

//   We mark the position before a token and then just increment the position. The token, then, can be retrieved by taking a substring from the mark to the position. This eliminates the need for
//   intermediate concatenations. In a couple of cases I've gone ahead and done them anyway -- these are for operators, where we grab the longest contiguous substring that is defined. I'm not too
//   worried about the O(n^2) complexity due to concatenation; they're bounded by four characters.

//   OK, so why use charAt() instead of regular expressions? It's a matter of asymptotic performance. V8 implements great regular expressions (O(1) in the match length for the (.*)$ pattern), but
//   the substring() method is O(n) in the number of characters returned. Firefox implements O(1) substring() but O(n) regular expression matching. Since there are O(n) tokens per document of n
//   characters, any O(n) step makes lexing quadratic. So I have to use the only reliably constant-time method provided by strings, charAt() (or in this case, charCodeAt()).

//   Of course, building strings via concatenation is also O(n^2), so I also avoid that for any strings that could be long. This is achieved by using a mark to indicate where the substring
//   begins, and advancing i independently. The span between mark and i is the substring that will be selected, and since each substring both requires O(n) time and consumes n characters, the
//   lexer as a whole is O(n). (Though perhaps with a large constant.)

//   Parse function.
//   As mentioned earlier, the parser and lexer aren't distinct. The lexer does most of the heavy lifting; it matches parens and brackets, arranges tokens into a hierarchical linked list, and
//   provides an index of those tokens by their fold order. It does all of this by streaming tokens into a micro-parser whose language is grouping and that knows about the oddities required to
//   handle regular expression cases. In the same function, though as a distinct case, the operators are folded and the syntax is compiled into a coherent tree form.

//   The input to the parse function can be anything whose toString() produces valid Javascript code.

    caterwaul_global.parse = function (input) {

//     Lex variables.
//     s, obviously, is the string being lexed. mark indicates the position of the stream, while i is used for lookahead. The difference is later read into a token and pushed onto the result. c
//     is a temporary value used to store the current character code. re is true iff a slash would begin a regular expression. esc is a flag indicating whether the next character in a string or
//     regular expression literal is escaped. exp indicates whether we've seen the exponent marker in a number. close is used for parsing single and double quoted strings; it contains the
//     character code of the closing quotation mark. t is the token to be processed.

//     Parse variables.
//     grouping_stack and gs_top are used for paren/brace/etc. matching. head and parent mark two locations in the linked syntax tree; when a new group is created, parent points to the opener
//     (i.e. (, [, ?, or {), while head points to the most recently added child. (Hence the somewhat complex logic in push().) indexes[] determines reduction order, and contains references to the
//     nodes in the order in which they should be folded. invocation_nodes is an index of the nodes that will later need to be flattened.

//     The push() function manages the mechanics of adding a node to the initial linked structure. There are a few cases here; one is when we've just created a paren group and have no 'head'
//     node; in this case we append the node as 'head'. Another case is when 'head' exists; in that case we update head to be the new node, which gets added as a sibling of the old head.

        var s = input.toString(), mark = 0, c = 0, re = true, esc = false, dot = false, exp = false, close = 0, t = '', i = 0, l = s.length, cs = function (i) {return s.charCodeAt(i)},
            grouping_stack = [], gs_top = null, head = null, parent = null, indexes = map(function () {return []}, parse_reduce_order), invocation_nodes = [], all_nodes = [empty],
            new_node = function (n) {return all_nodes.push(n), n}, push = function (n) {return head ? head._sibling(head = n) : (head = n._append_to(parent)), new_node(n)},
            syntax_node = this.syntax;

//     Trivial case.
//     The empty string will break the lexer because we won't generate a token (since we're already at the end). To prevent this we return an empty syntax node immediately, since this is an
//     accurate representation of no input.

        if (l === 0) return empty;

//     Main lex loop.
//     This loop takes care of reading all of the tokens in the input stream. At the end, we'll have a linked node structure with paren groups. At the beginning, we set the mark to the current
//     position (we'll be incrementing i as we read characters), munch whitespace, and reset flags.

        while ((mark = i) < l) {
          while (lex_space[c = cs(i)] && i < l) mark = ++i;
          esc = exp = dot = t = false;

//       Miscellaneous lexing.
//       This includes bracket resetting (the top case, where an open-bracket of any sort triggers regexp mode) and comment removal. Both line and block comments are removed by comparing against
//       lex_slash, which represents /, and lex_star, which represents *.

            if                                        (lex_bracket[c])                                                                    {t = !! ++i; re = lex_opener[c]}
       else if (c === lex_slash && cs(i + 1) === lex_star && (i += 2)) {while (++i < l && cs(i) !== lex_slash || cs(i - 1) !== lex_star);  t = !  ++i}
       else if            (c === lex_slash && cs(i + 1) === lex_slash) {while                              (++i < l && ! lex_eol[cs(i)]);  t = false}

//       Regexp and string literal lexing.
//       These both take more or less the same form. The idea is that we have an opening delimiter, which can be ", ', or /; and we look for a closing delimiter that follows. It is syntactically
//       illegal for a string to occur anywhere that a slash would indicate division (and it is also illegal to follow a string literal with extra characters), so reusing the regular expression
//       logic for strings is not a problem. (This follows because we know ahead of time that the Javascript is valid.)

       else if (lex_quote[c] && (close = c) && re && ! (re = ! (t = s.charAt(i)))) {while (++i < l && (c = cs(i)) !== close || esc)  esc = ! esc && c === lex_back;
                                                                                    while     (++i < l && lex_regexp_suffix[cs(i)])                               ; t = true}

//       Numeric literal lexing.
//       This is far more complex than the above cases. Numbers have several different formats, each of which requires some custom logic. The reason we need to parse numbers so exactly is that it
//       influences how the rest of the stream is lexed. One example is '0.5.toString()', which is perfectly valid Javascript. What must be output here, though, is '0.5', '.', 'toString', '(',
//       ')'; so we have to keep track of the fact that we've seen one dot and stop lexing the number on the second.

//       Another case is exponent-notation: 3.0e10. The hard part here is that it's legal to put a + or - on the exponent, which normally terminates a number. Luckily we can safely skip over any
//       character that comes directly after an E or e (so long as we're really in exponent mode, which I'll get to momentarily), since there must be at least one digit after an exponent.

//       The final case, which restricts the logic somewhat, is hexadecimal numbers. These also contain the characters 'e' and 'E', but we cannot safely skip over the following character, and any
//       decimal point terminates the number (since '0x5.toString()' is also valid Javascript). The same follows for octal numbers; the leading zero indicates that there will be no decimal point,
//       which changes the lex mode (for example, '0644.toString()' is valid).

//       So, all this said, there are different logic branches here. One handles guaranteed integer cases such as hex/octal, and the other handles regular numbers. The first branch is triggered
//       whenever a number starts with zero and is followed by 'x' or a digit (for conciseness I call 'x' a digit), and the second case is triggered when '.' is followed by a digit, or when a
//       digit starts.

//       A trivial change, using regular expressions, would reduce this logic significantly. I chose to write it out longhand because (1) it's more fun that way, and (2) the regular expression
//       approach has theoretically quadratic time in the length of the numbers, whereas this approach keeps things linear. Whether or not that actually makes a difference I have no idea.

//       Finally, in response to a recently discovered failure case, a period must be followed by a digit if it starts a number. The failure is the string '.end', which will be lexed as '.en',
//       'd' if it is assumed to be a floating-point number. (In fact, any method or property beginning with 'e' will cause this problem.)

       else if                  (c === lex_zero && lex_integer[cs(i + 1)]) {while (++i < l && lex_integer[cs(i)]); re = ! (t = true)}
       else if (lex_float[c] && (c !== lex_dot || lex_decimal[cs(i + 1)])) {while (++i < l && (lex_decimal[c = cs(i)] || (dot ^ (dot |= c === lex_dot)) || (exp ^ (exp |= lex_exp[c] && ++i))));
                                                                            while (i < l && lex_decimal[cs(i)]) ++i; re = ! (t = true)}

//       Operator lexing.
//       The 're' flag is reused here. Some operators have both unary and binary modes, and as a heuristic (which happens to be accurate) we can assume that anytime we expect a regular
//       expression, a unary operator is intended. The only exception are ++ and --, which are always unary but sometimes are prefix and other times are postfix. If re is true, then the prefix
//       form is intended; otherwise, it is postfix. For this reason I've listed both '++' and 'u++' (same for --) in the operator tables; the lexer is actually doing more than its job here by
//       identifying the variants of these operators.

//       The only exception to the regular logic happens if the operator is postfix-unary. (e.g. ++, --.) If so, then the re flag must remain false, since expressions like 'x++ / 4' can be valid.

       else if (lex_punct[c] && (t = re ? 'u' : '', re = true)) {while (i < l && lex_punct[cs(i)] && has(lex_op, t + s.charAt(i)))  t += s.charAt(i++); re = ! has(lex_postfix_unary, t)}

//       Identifier lexing.
//       If nothing else matches, then the token is lexed as a regular identifier or Javascript keyword. The 're' flag is set depending on whether the keyword expects a value. The nuance here is
//       that you could write 'x / 5', and it is obvious that the / means division. But if you wrote 'return / 5', the / would be a regexp delimiter because return is an operator, not a value. So
//       at the very end, in addition to assigning t, we also set the re flag if the word turns out to be an operator.

       else {while (++i < l && lex_ident[cs(i)]); re = has(lex_op, t = s.substring(mark, i))}

//       Token unification.
//       t will contain true, false, or a string. If false, no token was lexed; this happens when we read a comment, for example. If true, the substring method should be used. (It's a shorthand to
//       avoid duplicated logic.) For reasons that are not entirely intuitive, the lexer sometimes produces the artifact 'u;'. This is never useful, so I have a case dedicated to removing it.

        if (i === mark) throw new Error('Caterwaul lex error at "' + s.substr(mark, 40) + '" with leading context "' + s.substr(mark - 40, 40) + '" (probably a Caterwaul bug)');
        if (t === false) continue;
        t = t === true ? s.substring(mark, i) : t === 'u;' ? ';' : t;

//       Grouping and operator indexing.
//       Now that we have a token, we need to see whether it affects grouping status. There are a couple of possibilities. If it's an opener, then we create a new group; if it's a matching closer
//       then we close the current group and pop out one layer. (We don't check for matching here. Any code provided to Caterwaul will already have been parsed by the host Javascript interpreter,
//       so we know that it is valid.)

//       All operator indexing is done uniformly, left-to-right. Note that the indexing isn't strictly by operator. It's by reduction order, which is arguably more important. That's what the
//       parse_inverse_order table does: it maps operator names to parse_reduce_order subscripts. (e.g. 'new' -> 2.)

        t === gs_top ? (grouping_stack.pop(), gs_top = grouping_stack[grouping_stack.length - 1], head = head ? head.p : parent, parent = null) :
                       (has(parse_group, t) ? (grouping_stack.push(gs_top = parse_group[t]), parent = push(new_node(new syntax_node(t))), head = null) : push(new_node(new syntax_node(t))),
                        has(parse_inverse_order, t) && indexes[parse_inverse_order[t]].push(head || parent));           // <- This is where the indexing happens

//       Regexp flag special cases.
//       Normally a () group wraps an expression, so a following / would indicate division. The only exception to this is when we have a block construct; in this case, the next token appears in
//       statement-mode, which means that it begins, not modifies, a value. We'll know that we have such a case if (1) the immediately-preceding token is a close-paren, and (2) a block-accepting
//       syntactic form occurs to its left.

//       With all this trouble over regular expressions, I had to wonder whether it was possible to do it more cleanly. I don't think it is, unfortunately. Even lexing the stream backwards fails
//       to resolve the ambiguity:

//       | for (var k in foo) /foo/g.test(k) && bar();

//       In this case we won't know it's a regexp until we hit the 'for' keyword (or perhaps 'var', if we're being clever -- but a 'with' or 'if' would require complete lookahead). A perfectly
//       valid alternative parse, minus the 'for' and 'var', is this:

//       | ((k in foo) / (foo) / (g.test(k))) && bar();

//       The only case where reverse-lexing is useful is when the regexp has no modifiers.

        re |= t === ')' && head.l && has(parse_r_until_block, head.l.data)}

//     Operator fold loop.
//     This is the second major part of the parser. Now that we've completed the lex process, we can fold operators and syntax, and take care of some exception cases.

//     First step: functions, calls, dots, and dereferences.
//     I'm treating this differently from the generalized operator folding because of the syntactic inference required for call and dereference detection. Nothing has been folded at this point
//     (with the exception of paren groups, which is appropriate), so if the node to the left of any ( or [ group is an operator, then the ( or [ is really a paren group or array literal. If, on
//     the other hand, it is another value, then the group is a function call or a dereference. This folding goes left-to-right. The reason we also process dot operators is that they share the same
//     precedence as calls and dereferences. Here's what a () or [] transform looks like:

//     |   quux <--> foo <--> ( <--> bar                              quux <--> () <--> bar
//                             \                                               /  \                  <-- This can be done by saying _.l.wrap(new node('()')).p.fold_r().
//                              bif <--> , <--> baz       -->               foo    (                     _.l.wrap() returns l again, .p gets the wrapping node, and fold_r adds a child to it.
//                                                                                  \
//                                                                                   bif <--> , <--> baz

//     This is actually merged into the for loop below, even though it happens before other steps do (see 'Ambiguous parse groups').

//     Second step: fold operators.
//     Now we can go through the list of operators, folding each according to precedence and associativity. Highest to lowest precedence here, which is just going forwards through the indexes[]
//     array. The parse_index_forward[] array indicates which indexes should be run left-to-right and which should go right-to-left.

        for (var i = 0, l = indexes.length, forward, _; _ = indexes[i], forward = parse_index_forward[i], i < l; ++i)
          for (var j = forward ? 0 : _.length - 1, lj = _.length, inc = forward ? 1 : -1, node, data, ll; forward ? j < lj : j >= 0; j += inc)

//       Binary node behavior.
//       The most common behavior is binary binding. This is the usual case for operators such as '+' or ',' -- they grab one or both of their immediate siblings regardless of what they are.
//       Operators in this class are considered to be 'fold_lr'; that is, they fold first their left sibling, then their right.

            if (has(parse_lr, data = (node = _[j]).data))  node._fold_lr();

//       Ambiguous parse groups.
//       As mentioned above, we need to determine whether grouping constructs are invocations or real groups. This happens to take place before other operators are parsed (which is good -- that way
//       it reflects the precedence of dereferencing and invocation). The only change we need to make is to discard the explicit parenthetical or square-bracket grouping for invocations or
//       dereferences, respectively. It doesn't make much sense to have a doubly-nested structure, where we have a node for invocation and another for the group on the right-hand side of that
//       invocation. Better is to modify the group in-place to represent an invocation.

//       We can't solve this problem here, but we can solve it after the parse has finished. I'm pushing these invocation nodes onto an index for the end.

//       Sometimes we have a paren group that doesn't represent a value. This is the case for most control flow constructs:

//       | for (var k in o) (...)

//       We need to detect this and not fold the (var k in o)(...) as an invocation, since doing so would seriously break the resulting syntax.

//       There is an even more pathological case to consider. Firefox and other SpiderMonkey-based runtimes rewrite anonymous functions without parentheses, so you end up with stuff like this:

//       | function () {} ()

//       In this case we need to encode an invocation. Fortunately by this point the function node is already folded.

       else if (has(parse_ambiguous_group, data) && node.l && ! ((ll = node.l.l) && has(parse_r_until_block, ll.data)) &&
               (node.l.data === '.' || (node.l.data === 'function' && node.l.length === 2) ||
                                       ! (has(lex_op, node.l.data) ||
                                          has(parse_not_a_value, node.l.data))))  invocation_nodes.push(node.l._wrap(new_node(new syntax_node(data + parse_group[data]))).p._fold_r());

//       Unary left and right-fold behavior.
//       Unary nodes have different fold directions. In this case, it just determines which side we grab the node from. I'm glad that Javascript doesn't allow stuff like '++x++', which would make
//       the logic here actually matter. Because there isn't that pathological case, exact rigidity isn't required.

       else if (has(parse_l, data))  node._fold_l();
       else if (has(parse_r, data))  node._fold_r();

//       Ternary operator behavior.
//       This is kind of interesting. If we have a ternary operator, then it will be treated first as a group; just like parentheses, for example. This is the case because the ternary syntax is
//       unambiguous for things in the middle. So, for example, '3 ? 4 : 5' initially parses out as a '?' node whose child is '4'. Its siblings are '3' and '5', so folding left and right is an
//       obvious requirement. The only problem is that the children will be in the wrong order. Instead of (3) (4) (5), we'll have (4) (3) (5). So after folding, we do a quick swap of the first two
//       to set the ordering straight.

       else if (has(parse_ternary, data))  {node._fold_lr(); var temp = node[1]; node[1] = node[0]; node[0] = temp}

//       Grab-until-block behavior.
//       Not quite as simple as it sounds. This is used for constructs such as 'if', 'function', etc. Each of these constructs takes the form '<construct> [identifier] () {}', but they can also
//       have variants that include '<construct> () {}', '<construct> () statement;', and most problematically '<construct> () ;'. Some of these constructs also have optional child components; for
//       example, 'if () {} else {}' should be represented by an 'if' whose children are '()', '{}', and 'else' (whose child is '{}'). The tricky part is that 'if' doesn't accept another 'if' as a
//       child (e.g. 'if () {} if () {}'), nor does it accept 'for' or any number of other things. This discrimination is encoded in the parse_accepts table.

//       There are some weird edge cases, as always. The most notable is what happens when we have nesting without blocks:

//       | if (foo) bar; else bif;

//       In this case we want to preserve the semicolon on the 'then' block -- that is, 'bar;' should be its child; so the semicolon is required. But the 'bif' in the 'else' case shouldn't have a
//       semicolon, since that separates top-level statements. Because desperate situations call for desperate measures, there's a hack specifically for this in the syntax tree serialization.

//       One more thing. Firefox rewrites syntax trees, and one of the optimizations it performs on object literals is removing quotation marks from regular words. This means that it will take the
//       object {'if': 4, 'for': 1, etc.} and render it as {if: 4, for: 1, etc.}. As you can imagine, this becomes a big problem as soon as the word 'function' is present in an object literal. To
//       prevent this from causing problems, I only collapse a node if it is not followed by a colon. (And the only case where any of these would legally be followed by a colon is as an object
//       key.)

       else if (has(parse_r_until_block, data) && node.r && node.r.data !== ':')
                                                 {for (var count = 0, limit = parse_r_until_block[data]; count < limit && node.r && ! has(parse_block, node.r.data); ++count) node._fold_r();
                                                  node.r && (node.r.data === ';' ? node.push(empty) : node._fold_r());
                                                  if (has(parse_accepts, data) && parse_accepts[data] === (node.r && node.r.r && node.r.r.data)) node._fold_r().pop()._fold_r();
                                             else if (has(parse_accepts, data) && parse_accepts[data] === (node.r && node.r.data))               node._fold_r()}

//       Optional right-fold behavior.
//       The return, throw, break, and continue keywords can each optionally take an expression. If the token to the right is an expression, then we take it, but if the token to the right is a
//       semicolon then the keyword should be nullary.

       else if (has(parse_r_optional, data))  node.r && node.r.data !== ';' && node._fold_r();

//     Third step.
//     Find all elements with right-pointers and wrap them with semicolon nodes. This is necessary because of certain constructs at the statement-level don't use semicolons; they use brace syntax
//     instead. (e.g. 'if (foo) {bar} baz()' is valid, even though no semicolon precedes 'baz()'.) By this point everything else will already be folded. Note that this does some weird things to
//     associativity; in general, you can't make assumptions about the exact layout of semicolon nodes. Fortunately semicolon is associative, so it doesn't matter in practice. And just in case,
//     these nodes are 'i;' rather than ';', meaning 'inferred semicolon' -- that way it's clear that they aren't original. (They also won't appear when you call toString() on the syntax tree.)

        for (var i = all_nodes.length - 1, _; i >= 0; --i)  (_ = all_nodes[i]).r && _._wrap(new_node(new syntax_node('i;'))).p._fold_r();

//     Fourth step.
//     Flatten out all of the invocation nodes. As explained earlier, they are nested such that the useful data on the right is two levels down. We need to grab the grouping construct on the
//     right-hand side and remove it so that only the invocation or dereference node exists. During the parse phase we built an index of all of these invocation nodes, so we can iterate through
//     just those now. I'm preserving the 'p' pointers, though they're probably not useful beyond here.

        for (var i = 0, l = invocation_nodes.length, _, child; i < l; ++i)  (child = (_ = invocation_nodes[i])[1] = _[1][0] || empty) && (child.p = _);

        while (head.p) head = head.p;

//     Fifth step.
//     Prevent a space leak by clearing out all of the 'p', 'l', and 'r' pointers.

        for (var i = all_nodes.length - 1, _; i >= 0; --i)  delete (_ = all_nodes[i]).p, delete _.l, delete _.r;
        return head};
// Generated by SDoc 





// Environment-dependent compilation.
// It's possible to bind variables from 'here' (i.e. this runtime environment) inside a compiled function. The way we do it is to create a closure using a gensym. (Another reason that gensyms
// must really be unique.) Here's the idea. We use the Function constructor to create an outer function, bind a bunch of variables directly within that scope, and return the function we're
// compiling. The variables correspond to gensyms placed in the code, so the code will have closure over those variables.

// An optional second parameter 'environment' can contain a hash of variable->value bindings. These will be defined as locals within the compiled function.

// New in caterwaul 0.6.5 is the ability to specify a 'this' binding to set the context of the expression being evaluated.

// Caterwaul 1.0 and later automatically bind a variable called 'undefined' that is set to Javascript's 'undefined' value. This is done to defend against pathological cases of 'undefined' being
// set to something else. If you really wnat some other value of undefined, you can always bind it as an environment variable.

  (function () {var bound_expression_template = caterwaul_global.parse('var _bindings; return(_expression)'),
                    binding_template          = caterwaul_global.parse('_variable = _base._variable'),
                    undefined_binding         = caterwaul_global.parse('undefined = void(0)');

//   Compilation options.
//   Gensym renaming will break some things that expect the compiled code to be source-identical to the original tree. As a result, I'm introducing an options hash that lets you tell the compiler
//   things like "don't rename the gensyms this time around". Right now gensym_renaming is the only option, and it defaults to true.

    caterwaul_global.compile = function (tree, environment, options) {
      options = merge({gensym_renaming: true}, options);

      var bindings = merge({}, this._environment || {}, environment || {}, tree.bindings()), variables = [undefined_binding], s = gensym('base');
      for (var k in bindings) if (own.call(bindings, k) && k !== 'this') variables.push(binding_template.replace({_variable: k, _base: s}));

      var variable_definitions = new this.syntax(',', variables).unflatten(),
          function_body        = bound_expression_template.replace({_bindings: variable_definitions, _expression: tree});

      if (options.gensym_renaming) {var renaming_table = this.gensym_rename_table(function_body);
                                    for (var k in bindings) own.call(bindings, k) && (bindings[renaming_table[k] || k] = bindings[k]);
                                    function_body = function_body.replace(renaming_table);
                                    s             = renaming_table[s]}

      try       {return (new Function(s, function_body)).call(bindings['this'], bindings)}
      catch (e) {throw new Error(e + ' while compiling ' + function_body)}};

//   Gensym erasure.
//   Gensyms are horrible. They look like gensym_foo_1_5fz3ubq_10cbjq3C, which both takes up a lot of space and is hard to read. Fortunately, we can convert them at compile-time. This is possible
//   because Javascript (mostly) supports alpha-conversion for functions.

//   I said "mostly" because some symbols are converted into runtime strings; these are property keys. In the unlikely event that you've got a gensym being used to dereference something, e.g.
//   foo.gensym, then renaming is no longer safe. This, as far as I know, is the only situation where renaming won't work as intended. Because I can't imagine a situation where this would
//   actually arise, I'm not handling this case yet. (Though let me know if I need to fix this.)

//   New gensym names are chosen by choosing the smallest nonnegative integer N such that the gensym's name plus N.toString(36) doesn't occur as an identifier anywhere in the code. (The most
//   elegant option is to use scope analysis to keep N low, but I'm too lazy to implement it.)

    caterwaul_global.gensym_rename_table = function (tree) {
      var names = {}, gensyms = [], gensym_pattern = /^gensym_(.*)_\d+_[^_]+_[^_]+$/;
      tree.reach(function (node) {var d = node.data; gensym_pattern.test(d) && (names[d] || gensyms.push(d)); names[d] = d.replace(gensym_pattern, '$1') || 'anon'});

      var unseen_count = {}, next_unseen = function (name) {if (! (name in names)) return name;
                                                            var n = unseen_count[name] || 0; while (names[name + (++n).toString(36)]); return name + (unseen_count[name] = n).toString(36)};

      for (var renamed = {}, i = 0, l = gensyms.length, g; i < l; ++i) renamed[g = gensyms[i]] || (names[renamed[g] = next_unseen(names[g])] = true);
      return renamed}})();
// Generated by SDoc 






// Macroexpansion.
// Caterwaul's main purpose is to transform your code, and the easiest way to transform things is through macroexpansion. The idea is to locate syntax nodes with a given pattern and rewrite them
// somehow. For example, suppose we wanted to define a macro to enable the postfix /log modifier. Here's how it might look:

// | x /log   ->   (function (it) {console.log(it); return it})(x)

// The macro needs to first identify things of the form '_something /log' and transform them accordingly. Here's a macro to do that:

// | var m = caterwaul.macro('_something /log', '(function (it) {console.log(it); return it})(_something)');

//   Building macros.
//   Caterwaul gives you several ways to build macros. The simplest is to use caterwaul.macro() as shown above. It will parse each string, using the first as a pattern and the second as a
//   template. It then fills in the values on the right from the ones on the left and re-expands the result. In place of each string, caterwaul.macro() can take either a syntax tree or a
//   function. The function on the left should take a syntax tree, try to match the pattern against it, and return either a match object or false. The function on the right should take a match
//   object and return a new syntax tree. (It won't be invoked if the left function returned false.)

//   Macro function internals.
//   Caterwaul's macros are just functions from syntax to syntax. They return false if they don't match a particular node. So, for example, the macro '_x * 2' -> '_x << 1' would return 'a << 1'
//   on 'a * 2', but would return false on 'a * 3'. The macroexpander knows to descend into child nodes when a macroexpander returns false. If a macroexpander returns a value then that value is
//   taken and no further expansion is performed. (This is necessary if we want to implement literal macros -- that is, literal(x) -> x and x isn't macroexpanded further.)

//   If a macro wants to re-expand stuff it should use 'this.expand', which invokes the macroexpander on a tree. Most of the time macros will do this, and it's done automatically by
//   caterwaul.macro() when you use a string or a syntax tree as the expansion. You'll have to call this.expand() if you're using a function as an expander.

    caterwaul_global.ensure_syntax   = function (thing)    {return thing && thing.constructor === String ? this.parse(thing) : thing};

    caterwaul_global.ensure_pattern  = function (pattern)  {return pattern.constructor  === String      ? this.ensure_pattern(this.parse(pattern)) :
                                                                   pattern.constructor  === this.syntax ? function (tree) {return pattern.match(tree)} : pattern};

    caterwaul_global.ensure_expander = function (expander) {return expander.constructor === String      ? this.ensure_expander(this.parse(expander)) :
                                                                   expander.constructor === this.syntax ? function (match) {return this.expand(expander.replace(match))} : expander};

    caterwaul_global.macro = caterwaul_global.right_variadic(function (pattern, expander) {var new_pattern = this.ensure_pattern(pattern), new_expander = this.ensure_expander(expander);
                                                               return se(function (tree) {var match = new_pattern.call(this, tree); return match && new_expander.call(this, match)},
                                                                         function () {this.pattern = pattern, this.expander = expander})});

//   Macroexpander logic.
//   This behaves just like the pre-1.0 macroexpander, except that the patterns and expanders are now fused. The macro functions are also evaluated under a different context; rather than being
//   bound to the caterwaul function they came from, they are bound to a context object that gives them a way to re-expand stuff under the same set of macros. It also provides the caterwaul
//   function that is performing the expansion. (Though you shouldn't modify the macro list from inside a macro -- this pre-1.0 feature is now removed.)

//   Just like previous versions of caterwaul the macros are matched last-to-first. This means that the /last/ matching macro is used, allowing you to easily override stuff. Also, the
//   macroexpand() function takes optional extra parameters; these are either macros or arrays of macros to be added to the macro list stored on the caterwaul function.

    caterwaul_global.macroexpand = function (tree) {for (var macros = arguments.length ? [].concat(this._macros || []) : this._macros || [], i = 1, l = arguments.length, x; i < l; ++i)
                                                      (x = arguments[i]) instanceof Array ? macros.push.apply(macros, x) : macros.push(x);

                                                    var context = {caterwaul: this, macros: macros, expand: function (tree) {
                                                      return tree.rmap(function (node) {
                                                        for (var new_node = null, i = macros.length - 1; i >= 0; --i) if (new_node = macros[i].call(context, node)) return new_node})}};

                                                    return context.expand(this.ensure_syntax(tree))};
// Generated by SDoc 






// Precompilation support.
// This makes caterwaul precompilation-aware ahead of time. I'm doing this so that you can precompile caterwaul itself, which used to be responsible for a fair amount of loading time.

  var precompiled_internal_table = {};
  caterwaul_global.precompiled_internal = function (f) {var k = gensym('precompiled'); return precompiled_internal_table[k] = f, k};
  caterwaul_global.is_precompiled       = function (f) {return f.constructor === String && precompiled_internal_table[f]};
// Generated by SDoc 





// Init method.
// This runs a compilation stage. If the input is a function or string, then the function or string is parsed, run through the macroexpander, and compiled.

  caterwaul_global.clone = function (f) {return se(this.merge(calls_init(), this, this.instance_methods(), {constructor: this}), function () {
                                                  delete this._id, delete this._macros, delete this._environment})};

//   Compiler instance methods/attributes.
//   These are installed on each generated compiler function. You can change some of them if you know what you're doing (for instance, you can create a compiler for a different programming
//   language by changing the 'parse' function to handle different input). Unlike caterwaul < 1.0 there is no support for cloning a compiler function. However, you can compose things nicely by
//   doing stuff like this:

//   | var my_caterwaul    = caterwaul(function (code) {...});
//     var other_caterwaul = caterwaul(my_caterwaul);
//     other_caterwaul.parse = function (x) {...};

//   In this example, other_caterwaul delegates its macroexpansion to my_caterwaul, but it uses a custom parse function.

    caterwaul_global.instance_methods = function () {
      return {compile:              this.compile,
              parse:                this.parse,
              macroexpand:          this.macroexpand,
              syntax:               this.syntax,
              ref:                  this.ref,
              id:                   this.syntax_common.id,

              gensym_rename_table:  this.gensym_rename_table,

              init_function:        this.init_function || this.macroexpand,
              instance_methods:     this.instance_methods,

              ensure_syntax:        this.ensure_syntax,
              ensure_pattern:       this.ensure_pattern,
              ensure_expander:      this.ensure_expander,

              environment:          function (e) {return arguments.length ? (this._environment = e, this)                              : this._environment},
              macros:               function ()  {return arguments.length ? (this._macros = this.flatten.apply(this, arguments), this) : this._macros},

              toString:             function () {return '[caterwaul instance ' + this.id() + ']'},

              init:                 function (f, environment) {return this.is_precompiled(f) || this.init_not_precompiled(f, environment)},
              init_not_precompiled: function (f, environment) {return f.constructor === this.syntax ? this.init_function(f) : this.compile(this(this.parse(f)), environment)}}};
// Generated by SDoc 




  return caterwaul = caterwaul_global = caterwaul_global.clone()});
// Generated by SDoc 



caterwaul.version('4b8cac35fdce9b46bbf8b5eacd1a3b6b');
// Generated by SDoc 

__
meta::cached_dependency('caterwaul.std.js', <<'__');
 (function($) {$.anonymizer=function( ) {for(var translation_table= { } ,i=0,l=arguments.length;
i<l;
 ++i)translation_table[arguments[i] ] =$.gensym(arguments[i] ) ;
return function(node) {return $.ensure_syntax(node) .replace(translation_table) } } } ) (caterwaul) ;
 (function($) {var loop_anon=$.anonymizer( 'i' , 'l' , 'xs' , 'result' ) ;
$.word_macros=function(language) {return[language.modifier( 'qs' ,function(match) {return new $.ref(match._expression, 'qs' ) } ) ,language.modifier( 'qse' ,function(match) {return new $.ref(this.expand(match._expression) , 'qse' ) } ) ,language.modifier( 'reexpand' ,function(match) {return this.expand(this.expand(match._expression) ) } ) ,language.modifier( 'noexpand' ,function(match) {return match._expression} ) ,language.modifier( 'wobbly' , 'chuck' , 'raise' , '(function () {throw _expression}).call(this)' ) ,language.parameterized_modifier( 'failover' , 'safely' , 'rescue' , '(function () {try {return (_expression)} catch (e) {return (_parameters)}}).call(this)' ) ,language.parameterized_modifier( 'given' , '(function (_parameters) {return _expression})' ) ,language.parameterized_modifier( 'bgiven' , '(function (t, f) {return (function () {return f.apply(t, arguments)})})(this, (function (_parameters) {return _expression}))' ) ,language.modifier( 'delay' , '(function (t, f) {return (function () {return f.call(t)})})(this, (function () {return _expression}))' ) ,language.modifier( 'lazy' , '(function (t, f, v, vc) {return (function () {return vc ? v : (vc = true, v = f.call(t))})})(this, (function () {return _expression}))' ) ,language.parameterized_modifier( 'effect' , 'se' , '(function (it) {return (_parameters), it}).call(this, (_expression))' ) ,language.parameterized_modifier( 'then' , 're' , 'returning' , '(function (it) {return (_parameters)}).call(this, (_expression))' ) ,language.parameterized_modifier( 'where' , 'bind' , '(function () {var _parameters; return (_expression)}).call(this)' ) ,language.parameterized_modifier( 'when' , '((_parameters) && (_expression))' ) ,language.parameterized_modifier( 'unless' , '(! (_parameters) && (_expression))' ) ,language.parameterized_modifier( 'otherwise' , '((_expression) || (_parameters))' ) ,language.parameterized_modifier( 'when_defined' , '((_parameters) != null && (_expression))' ) ,language.parameterized_modifier( 'unless_defined' , '((_parameters) == null && (_expression))' ) ,language.parameterized_modifier( 'over' ,loop_anon( '(function () {for (var xs = (_parameters), result = [], i = 0, l = xs.length, it; i < l; ++i)' + 'it = xs[i], result.push(_expression); return result}).call(this)' ) ) ,language.parameterized_modifier( 'over_keys' ,loop_anon( '(function () {var x = (_parameters), result = []; ' + 'for (var it in x) Object.prototype.hasOwnProperty.call(x, it) && result.push(_expression); return result}).call(this)' ) ) ,language.parameterized_modifier( 'over_values' ,loop_anon( '(function () {var x = (_parameters), result = [], it; ' + 'for (var k in x) Object.prototype.hasOwnProperty.call(x, k) && (it = x[k], result.push(_expression));' + 'return result}).call(this)' ) ) ,language.parameterized_modifier( 'until' ,loop_anon( '(function () {var result = []; while (! (_parameters)) result.push(_expression); return result}).call(this)' ) ) ] } } ) (caterwaul) ;
 (function($) {$.js=function( ) {var macro=function(name,expander) {return function(template) {return $.macro($.parse(template) .replace( {_modifiers:$.parse(name) } ) ,expander) } } ;
var macros=function(name,expander) {return function(template) {return result.modifier($.parse(template) .replace( {_modifiers:$.parse(name) } ) ,expander) } } ;
var result= {modifier:this.right_variadic(function(name,expander) {return $.map(macro(name,expander) , [ '_expression /_modifiers' , '_expression -_modifiers' , '_expression |_modifiers' , '_modifiers[_expression]' , '_modifiers in _expression' , '_expression, _modifiers' ] ) } ) ,parameterized_modifier:this.right_variadic(function(name,expander) {return[$.map(macros(name,expander) , [ '_modifiers[_parameters]' , '_modifiers._parameters' ] ) ,$.map(macro(name,expander) , [ '_expression <_modifiers> _parameters' , '_expression -_modifiers- _parameters' ] ) ] } ) ,macros: [function(node) {var s=node.data,q=s.charAt(0) ,syntax=$.syntax;
if(q!== '\'' &&q!== '"' || ! /#\{[^\}]+\}/ .test(s) )return false;
for(var pieces= [ ] ,i=1,l=s.length-1,brace_depth=0,got_hash=false,start=1,c;
i<l;
 ++i)if(brace_depth)if( (c=s.charAt(i) ) === '}' ) --brace_depth||pieces.push(s.substring(start,i) ) && (start=i+1) ,got_hash=false;
else brace_depth+=c=== '{' ;
else if( (c=s.charAt(i) ) === '#' )got_hash=true;
else if(c=== '{' &&got_hash)pieces.push(s.substring(start,i-1) ) ,start=i+1, ++brace_depth;
else got_hash=false;
pieces.push(s.substring(start,l) ) ;
for(var quoted=new RegExp( '\\\\' +q, 'g' ) ,i=0,l=pieces.length;
i<l;
 ++i)pieces[i] =i&1?this.expand($.parse(pieces[i] .replace(quoted,q) ) .as( '(' ) ) :new syntax(q+pieces[i] +q) ;
return new syntax( '+' ,pieces) .unflatten() .as( '(' ) } ,this.macro( '_left(_args) = _right' , '_left = (function (_args) {return _right})' ) ,this.macro( '_left(_var = arguments) = _right' , '_left = (function () {var _var = arguments; return _right})' ) ] } ;
return result} } ) (caterwaul) ;
caterwaul.js_base=function( ) {var js=this.js() ;
return this.clone() .macros(this.word_macros(js) ,js.macros) } ;
caterwaul.js_base() (caterwaul.precompiled_internal( (function( ) {null;
return(function($) {$.seq_macro= (function(language) {return language.modifier( 'seq' , (function( ) {var seq_expand=$.seq() ;
return( (function(tree) {return this.expand(seq_expand(tree._expression) ) } ) ) } ) .call(this) ) } ) ;
$.seq= (function() {return(function( ) {var anon=$.anonymizer( 'S' ) ,rule= (function(p,e) {return $.macro(anon(p) ,e.constructor===Function? (function(match) {return this.expand(e.call(this,match) ) } ) :anon(e) ) } ) ,operator_macros= (function( ) {var operator_pattern= (function(op,normal,bang,tbang) {return(function( ) {var template= (function(p) {return anon(p) .replace( { '+' :op} ) } ) ,trule= (function(p,e) {return rule(template(p) ,e.constructor===Function?e:template(e) ) } ) ,context_conversions= [trule( 'S[_xs +~[_f]]' , 'S[_xs +[S[_f]]]' ) ,trule( 'S[_xs +~_var[_f]]' , 'S[_xs +_var[S[_f]]]' ) ,trule( 'S[_xs +!~[_f]]' , 'S[_xs +![S[_f]]]' ) ,trule( 'S[_xs +!~_var[_f]]' , 'S[_xs +!_var[S[_f]]]' ) ,trule( 'S[_xs +~!~[_f]]' , 'S[_xs +~![S[_f]]]' ) ,trule( 'S[_xs +~!~_var[_f]]' , 'S[_xs +~!_var[S[_f]]]' ) ] ;
return( (function(it) {return(it.concat(context_conversions) ) } ) .call(this, ( (function(it) {return( ( (tbang) && (it.push(trule( 'S[_xs +~![_f]]' ,tbang) ,trule( 'S[_xs +~!_var[_f]]' ,tbang) ) ) ) ) ,it} ) .call(this, ( (function(it) {return( ( (bang) && (it.push(trule( 'S[_xs +![_f]]' ,bang) ,trule( 'S[_xs +!_var[_f]]' ,bang) ) ) ) ) ,it} ) .call(this, ( (function(it) {return(it.push(trule( 'S[_xs +[_f]]' ,normal) ,trule( 'S[_xs +_var[_f]]' ,normal) ) ) ,it} ) .call(this, ( [ ] ) ) ) ) ) ) ) ) ) } ) .call(this) } ) ,binary_operator= (function(op,f) {return(function( ) {var t= (function(pattern) {return anon(pattern) .replace( { '+' :op} ) } ) ;
return(rule(t( 'S[_xs + _ys]' ) ,f) ) } ) .call(this) } ) ,loop_anon=$.anonymizer( 'xs' , 'ys' , 'x' , 'y' , 'i' , 'j' , 'l' , 'lj' ) ,loop_form= (function(x) {return loop_anon(scoped(anon(x) ) ) } ) ,scope=anon( '(function (xs) {_body}).call(this, S[_xs])' ) ,scoped= (function(tree) {return scope.replace( {_body:tree} ) } ) ,op_form= (function(pattern) {return(function( ) {var form=loop_form(pattern) ;
return( (function(match) {return form.replace(variables_for(match) ) } ) ) } ) .call(this) } ) ,map=op_form( 'for (var ys = [], _xi = 0, _xl = xs.length, _x; _xi < _xl; ++_xi) _x = xs[_xi], ys.push((_f));                          return ys' ) ,each=op_form( 'for (var          _xi = 0, _xl = xs.length, _x; _xi < _xl; ++_xi) _x = xs[_xi], (_f);                                   return xs' ) ,flatmap=op_form( 'for (var ys = [], _xi = 0, _xl = xs.length, _x; _xi < _xl; ++_xi) _x = xs[_xi], ys.push.apply(ys, ys.slice.call((_f))); return ys' ) ,filter=op_form( 'for (var ys = [], _xi = 0, _xl = xs.length, _x; _xi < _xl; ++_xi) _x = xs[_xi], (_f) && ys.push(_x);                    return ys' ) ,filter_not=op_form( 'for (var ys = [], _xi = 0, _xl = xs.length, _x; _xi < _xl; ++_xi) _x = xs[_xi], (_f) || ys.push(_x);                    return ys' ) ,map_filter=op_form( 'for (var ys = [], _xi = 0, _xl = xs.length, _x, _y; _xi < _xl; ++_xi) _x = xs[_xi], (_y = (_f)) && ys.push(_y);         return ys' ) ,foldl=op_form( 'for (var _x = xs[0], _xi = 1, _xl = xs.length, _x0;            _xi < _xl; ++_xi) _x0 = xs[_xi], _x = (_f);              return _x' ) ,foldr=op_form( 'for (var _xl = xs.length - 1, _xi = _xl - 1, _x0 = xs[_xl], _x; _xi >= 0; --_xi) _x = xs[_xi], _x0 = (_f);              return _x0' ) ,exists=op_form( 'for (var _x = xs[0], _xi = 0, _xl = xs.length, x; _xi < _xl; ++_xi) {_x = xs[_xi]; if (y = (_f)) return y} return false' ) ,concat=op_form( 'return xs.concat(S[_ys])' ) ,zip=op_form( 'for (var ys = S[_ys], pairs = [], i = 0, l = xs.length; i < l; ++i) pairs.push([xs[i], ys[i]]); return pairs' ) ,cross=op_form( 'for (var ys = S[_ys], pairs = [], i = 0, l = xs.length, lj = ys.length; i < l; ++i) ' + 'for (var j = 0; j < lj; ++j) pairs.push([xs[i], ys[j]]);' + 'return pairs' ) ,variables_for= (function(m) {return $.merge( { } ,m,prefixed_hash(m._var) ) } ) ,prefixed_hash= (function(p) {return(function( ) {var name=p&&p.data|| 'x' ;
return( {_x:name,_xi: ( '' + (name) + 'i' ) ,_xl: ( '' + (name) + 'l' ) ,_x0: ( '' + (name) + '0' ) } ) } ) .call(this) } ) ;
return( [rule( 'S[_x]' , '_x' ) ,rule( 'S[_x, _y]' , 'S[_x], S[_y]' ) ,operator_pattern( '|' ,exists) ,rule( 'S[(_x)]' , '(S[_x])' ) ,operator_pattern( '*' ,map,each,flatmap) ,binary_operator( '+' ,concat) ,operator_pattern( '%' ,filter,filter_not,map_filter) ,binary_operator( '-' ,cross) ,operator_pattern( '/' ,foldl,foldr) ,binary_operator( '^' ,zip) ] ) } ) .call(this) ,word_macros= (function( ) {var n= (function(match) {return n_pattern.replace($.merge( {_lower: '0' ,_step: '1' } ,match) ) } ) ,n_pattern=anon( '(function (i, u, s) {if ((u - i) * s <= 0) return [];' + 'for (var r = [], d = u - i; d > 0 ? i < u : i > u; i += s) r.push(i); return r})((_lower), (_upper), (_step))' ) ,scope=$.parse( '(function () {_body}).call(this)' ) ,scoped= (function(t) {return scope.replace( {_body:t} ) } ) ,form= (function(p) {return(function(match) {return scoped(anon(p) ) .replace(match) } ) } ) ,keys=form( 'var ks = [], o = S[_o]; for (var k in o) Object.prototype.hasOwnProperty.call(o, k) && ks.push(k); return ks' ) ,values=form( 'var vs = [], o = S[_o]; for (var k in o) Object.prototype.hasOwnProperty.call(o, k) && vs.push(o[k]); return vs' ) ,pairs=form( 'var ps = [], o = S[_o]; for (var k in o) Object.prototype.hasOwnProperty.call(o, k) && ps.push([k, o[k]]); return ps' ) ,object=form( 'for (var o = {}, xs = S[_xs], i = 0, l = xs.length, x; i < l; ++i) x = xs[i], o[x[0]] = x[1]; return o' ) ;
return( [rule( 'S[n[_upper]]' ,n) ,rule( 'S[_o /keys]' ,keys) ,rule( 'S[_xs |object]' ,object) ,rule( 'S[n[_lower, _upper]]' ,n) ,rule( 'S[_o /values]' ,values) ,rule( 'S[_xs -object]' ,object) ,rule( 'S[n[_lower, _upper, _step]]' ,n) ,rule( 'S[_o /pairs]' ,pairs) ,rule( 'S[_xs /object]' ,object) ] ) } ) .call(this) ;
return( (function(it) {return(it.init_function= (function(tree) {return this.macroexpand(anon( 'S[_x]' ) .replace( {_x:tree} ) ) } ) ) ,it} ) .call(this, ($.clone() .macros(operator_macros,word_macros) ) ) ) } ) .call(this) } ) } ) } ) .call(this) ) ) (caterwaul) ;
caterwaul.js_base() (caterwaul.precompiled_internal( (function( ) {null;
return(function($) { (function( ) {var overload_unary= (function(op) {return $.macro( ( '' + (op) + ' _x' ) , ( '_x["' + ( /[a-z]/ .test(op) ?op: "u" +op) + '"]()' ) ) } ) ,overload_binary= (function(op) {return $.macro( ( '_x ' + (op) + ' _y' ) , ( '_x["' + (op) + '"](_y)' ) ) } ) ,qw= (function(s) {return s.split( /\s+/ ) } ) ,unary_operators= (function( ) {for(var xs= (qw( '! ~ + - new void typeof' ) ) ,result1= [ ] ,i1=0,l1=xs.length,it;
i1<l1;
 ++i1)it=xs[i1] ,result1.push(overload_unary(it) ) ;
return result1} ) .call(this) ,binary_operators= (function( ) {for(var xs= (qw( '+ - * / % ^ | & << >> >>> += -= *= /= %= ^= |= &= <<= >>= >>>= == != === !== < > <= >= in instanceof' ) ) ,result1= [ ] ,i1=0,l1=xs.length,it;
i1<l1;
 ++i1)it=xs[i1] ,result1.push(overload_binary(it) ) ;
return result1} ) .call(this) ;
return($.overload_macro= (function(language) {return language.modifier( 'overload' , (function( ) {var overload_expand=$.overload() ;
return( (function(tree) {return this.expand(overload_expand(tree._expression) ) } ) ) } ) .call(this) ) } ) ,$.overload= (function() {return $.clone() .macros(unary_operators,binary_operators) } ) ) } ) .call(this) } ) } ) .call(this) ) ) (caterwaul) ;
caterwaul.js_all=function( ) {var js=this.js() ;
return this.clone() .macros(this.word_macros(js) ,js.macros,this.overload_macro(js) ,this.seq_macro(js) ) } ;

__
meta::configuration('dependencies', <<'__');
# Named dependencies:
caterwaul.js: http://caterwauljs.org/build/caterwaul.js
caterwaul.std.js: http://caterwauljs.org/build/extensions/std.pre.js
#caterwaul.dev.js: http://caterwauljs.org/build/extensions/dev.pre.js
__
meta::data('default-action', 'shell');
meta::data('libraries', <<'__');
# URLs of libraries to be downloaded into the lib/ directory.
http://spencertipping.com/caterwaul/caterwaul.all.js
http://spencertipping.com/montenegro/montenegro.server.js
__
meta::data('license', <<'__');
MIT License
Copyright (c) 2010 Spencer Tipping

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
__
meta::data('main', 'server.js');
meta::data('name', 'node-base');
meta::data('permanent-identity', '36c766fa1297d04c8ddc4b937e125738');
meta::data('quiet', '1');
meta::data('watching', '1');
meta::function('alias', <<'__');
my ($name, @stuff) = @_;
return ls('-a', '^alias::') unless defined $name;
@stuff ? around_hook('alias', @_, sub {associate("alias::$name", join(' ', @stuff), execute => 1)}) : retrieve("alias::$name") || "Undefined alias $name";

__
meta::function('cat', 'join "\\n", retrieve(@_);');
meta::function('cc', <<'__');
# Stashes a quick one-line continuation. (Used to remind me what I was doing.)
@_ ? associate('data::current-continuation', hook('set-cc', join(' ', @_))) : retrieve('data::current-continuation');
__
meta::function('ccc', 'rm(\'data::current-continuation\');');
meta::function('child', <<'__');
around_hook('child', @_, sub {
  my ($child_name) = @_;
  clone($child_name);
  enable();
  qx($child_name update-from $0 -n);
  disable()});
__
meta::function('clone', <<'__');
for (grep length, @_) {
  around_hook('clone', $_, sub {
    hypothetically(sub {
      rm('data::permanent-identity');
      file::write($_, serialize(), noclobber => 1);
      chmod(0700, $_)})})}
__
meta::function('cp', <<'__');
my $from = shift @_;
my $value = retrieve($from);
associate($_, $value) for @_;
__
meta::function('create', <<'__');
my ($name, $value) = @_;
around_hook('create', $name, $value, sub {
  return edit($name) if exists $data{$name};
  associate($name, defined $value ? $value : '');
  edit($name) unless defined $value});
__
meta::function('current-state', 'serialize(\'-pS\');');
meta::function('disable', 'hook(\'disable\', chmod_self(sub {$_[0] & 0666}));');
meta::function('dupdate', <<'__');
# Update the repository based on the dependencies it lists. These dependencies
# can be anything that's retrievable.

# If you have any ::s in the local name of the dependency, then the cached_dependency::
# prefix won't be added. This lets you import slices of other objects and have
# those slices merge into any namespace you'd like.

rm(grep /^cached_dependency::/, keys %data);
my %dependencies = map &{attribute($_)}(), select_keys('--criteria' => "^configuration::depend.*");

for (keys %dependencies) {
  terminal::info("Retrieving $dependencies{$_} as $_");
  my $prefix = /::/ ? '' : 'cached_dependency::';
  associate("${prefix}$_", retrieve($dependencies{$_}))}

reload();

__
meta::function('edit', <<'__');
my ($name, %options) = @_;
my $extension = extension_for($name);

die "$name is virtual or does not exist" unless exists $data{$name};
die "$name is inherited; use 'edit $name -f' to edit anyway" unless is($name, '-u') || is($name, '-d') || exists $options{'-f'};

around_hook('edit', @_, sub {
  associate($name, invoke_editor_on($data{$name} // '', %options, attribute => $name, extension => $extension), execute => 1)});
save() unless $data{'data::edit::no-save'};
'';
__
meta::function('enable', 'hook(\'enable\', chmod_self(sub {$_[0] | $_[0] >> 2}));');
meta::function('export', <<'__');
# Exports data into a text file.
#   export attr1 attr2 attr3 ... file.txt
my $name = pop @_;
@_ or die 'Expected filename';
file::write($name, join "\n", retrieve(@_));
__
meta::function('extern', '&{$_[0]}(retrieve(@_[1 .. $#_]));');
meta::function('grep', <<'__');
# Looks through attributes for a pattern. Usage is grep pattern [options], where
# [options] is the format as provided to select_keys.

my ($pattern, @args)     = @_;
my ($options, @criteria) = separate_options(@args);
my @attributes           = select_keys(%$options, '--criteria' => join('|', @criteria));

$pattern = qr/$pattern/;

my @m_attributes;
my @m_line_numbers;
my @m_lines;

for my $k (@attributes) {
  next unless length $k;
  my @lines = split /\n/, retrieve($k);
  for (0 .. $#lines) {
    next unless $lines[$_] =~ $pattern;
    push @m_attributes,   $k;
    push @m_line_numbers, $_ + 1;
    push @m_lines,        '' . ($lines[$_] // '')}}

unless ($$options{'-C'}) {
  s/($pattern)/\033[1;31m\1\033[0;0m/g for @m_lines;
  s/^/\033[1;34m/o for @m_attributes;
  s/^/\033[1;32m/o && s/$/\033[0;0m/o for @m_line_numbers}

table_display([@m_attributes], [@m_line_numbers], [@m_lines]);
__
meta::function('hash', 'fast_hash(@_);');
meta::function('hook', <<'__');
my ($hook, @args) = @_;
$transient{active_hooks}{$hook} = 1;
dangerous('', sub {&$_(@args)}) for grep /^hook::${hook}::/, sort keys %data;
@args;
__
meta::function('hooks', 'join "\\n", sort keys %{$transient{active_hooks}};');
meta::function('identity', 'retrieve(\'data::permanent-identity\') || associate(\'data::permanent-identity\', fast_hash(rand() . name() . serialize()));');
meta::function('import', <<'__');
my $name = pop @_;
associate($name, @_ ? join('', map(file::read($_), @_)) : join('', <STDIN>)); 
__
meta::function('initial-state', '$transient{initial};');
meta::function('is', <<'__');
my ($attribute, @criteria) = @_;
my ($options, @stuff) = separate_options(@criteria);
exists $data{$attribute} and attribute_is($attribute, %$options);

__
meta::function('load-state', <<'__');
around_hook('load-state', @_, sub {
  my ($state_name) = @_;
  my $state = retrieve("state::$state_name");

  terminal::state('saving current state into _...');
  save_state('_');

  delete $data{$_} for grep ! /^state::/, keys %data;
  %externalized_functions = ();

  terminal::state("restoring state $state_name...");
  meta::eval_in($state, "state::$state_name");
  terminal::error(hook('load-state-failed', $@)) if $@;
  reload();
  verify()});

__
meta::function('loc', <<'__');
# Counts SLOC, whitespace, and total LOC in the codebase.
hook('before-loc', @_);

my $criteria    = join '|', @_;
my @attributes  = grep s/^sdoc:://, select_keys('--criteria' => $criteria);
my $tcomments   = 0;
my $twhitespace = 0;
my $tsource     = 0;

my $line = sub {
  my ($source, $whitespace, $comments, $name) = @_;
  $source ||= 1;                # Prevent divide-by-zero errors
  sprintf "%5d total, %4d SLOC, %5d[%4d%%] whitespace, %5d[%4d%%] comment [%s]",
          $source + $whitespace + $comments, $source, $whitespace, int($whitespace / $source * 100), $comments, int($comments / $source * 100), $name};

my $loc = sub {
  my @lines    = map split(/\n/, $_), retrieve($_[0]);
  $tcomments   += (my $comments   = grep /^\s*\/\// || /^\s*#/, @lines);
  $twhitespace += (my $whitespace = grep /^\s*$/, @lines);
  $tsource     += (my $source     = @lines - $comments - $whitespace);
  &$line($source, $whitespace, $comments, $_[0])};

terminal::info(map &$loc($_), @attributes);
terminal::info(&$line($tsource, $twhitespace, $tcomments, 'total'));

hook('after-loc', @_);
__
meta::function('lock', 'hook(\'lock\', chmod_self(sub {$_[0] & 0555}));');
meta::function('ls', <<'__');
my ($options, @criteria) = separate_options(@_);
my ($external, $shadows, $sizes, $flags, $long, $hashes, $parent_hashes) = @$options{qw(-e -s -z -f -l -h -p)};
$sizes = $flags = $hashes = $parent_hashes = 1 if $long;

return table_display([grep ! exists $data{$externalized_functions{$_}}, sort keys %externalized_functions]) if $shadows;

my $criteria    = join('|', @criteria);
my @definitions = select_keys('--criteria' => $criteria, %$options);

my %inverses  = map {$externalized_functions{$_} => $_} keys %externalized_functions;
my @externals = map $inverses{$_}, grep length, @definitions;
my @internals = grep length $inverses{$_}, @definitions;
my @sizes     = map sprintf('%6d %6d', length(serialize_single($_)), length(retrieve($_))), @{$external ? \@internals : \@definitions} if $sizes;

my @flags     = map {my $k = $_; join '', map(is($k, "-$_") ? $_ : '-', qw(d i m u))} @definitions if $flags;
my @hashes    = map fast_hash(retrieve($_)), @definitions if $hashes;

my %inherited     = parent_attributes(grep /^parent::/o, keys %data) if $parent_hashes;
my @parent_hashes = map $inherited{$_} || '-', @definitions if $parent_hashes;

join "\n", map strip($_), split /\n/, table_display($external ? [grep length, @externals] : [@definitions],
                                                    $sizes ? ([@sizes]) : (), $flags ? ([@flags]) : (), $hashes ? ([@hashes]) : (), $parent_hashes ? ([@parent_hashes]) : ());
__
meta::function('mv', <<'__');
my ($from, $to) = @_;
die "'$from' does not exist" unless exists $data{$from};
associate($to, retrieve($from));
rm($from);
__
meta::function('name', <<'__');
my $name = $0;
$name =~ s/^.*\///;
$name;
__
meta::function('node', <<'__');
# Runs node on a collection of source files and arguments. The format is:
# node([@source_strings], @process_args);
my ($sources, @args) = @_;

with_exported(@$sources, sub {
  hook('before-node', $_[0], @args);
  sh('node', $_[0], @args);
  hook('after-node', $_[0], @args);
});
__
meta::function('node-custom', <<'__');
# Runs node on a collection of source files and arguments. The format is:
# &{'node-custom'}([@source_strings], [@node_arguments], @process_args);
my ($sources, $node_args, @args) = @_;

with_exported(@$sources, sub {
  hook('before-node-custom', @$node_args, $_[0], @args);
  sh('node', @$node_args, $_[0], @args);
  hook('after-node-custom', @$node_args, $_[0], @args);
});
__
meta::function('note', <<'__');
# Creates a note with a given name, useful for jotting things down.
create("note::$_[0]");
__
meta::function('notes', 'ls(\'-a\', \'^note::\');');
meta::function('parents', 'join "\\n", grep s/^parent:://o, sort keys %data;');
meta::function('parse-todo', <<'__');
# Takes a string of todo text and parses it. Multiple todo lists can be
# combined, resulting in a longer list.
my @todo_paragraphs = grep s/^\h*\|//, split /\n{2,}/, join "\n\n", retrieve(@_);
my @todo_lines      = grep /^\h*\[\W+\]\h*\w/, map split(/\n/), @todo_paragraphs;

sub progress_of {my ($s) = @_; ($s =~ /^(\S*)/ and length $1) / length $s}

map /^\s*\[(\W+)\]\h*(\H+)\h*(.*)$/ && {progress_meter => $1, progress => progress_of($1), category => $2, details => $3}, @todo_lines;

__
meta::function('perl', <<'__');
my $result = eval(join ' ', @_);
$@ ? terminal::error($@) : $result;
__
meta::function('precompile', <<'__');
# Precompiles an HTML file to include all of its dependencies. The output is
# written to stdout.

my ($html) = retrieve(@_);
my @pieces = split /(<script[^>]+src=["']([^"']+)['"]>\s*<\/script>|<link rel=["']stylesheet["'][^>]href=["']([^'"]+)["'](?:\/>|>\s*<\/link>))/, $html;

my @new_pieces;
for (0 .. $#pieces) {
  push @new_pieces, $pieces[$_] if $_ % 4 == 0;

  push @new_pieces, '<script>' . retrieve($pieces[$_ + 1]) . '</script>' if $_ % 4 == 1 && $pieces[$_] =~ /<script/;
  push @new_pieces, '<style>'  . retrieve($pieces[$_ + 2]) . '</style>'  if $_ % 4 == 1 && $pieces[$_] =~ /<link/;}

join '', @new_pieces;

__
meta::function('preprocess', <<'__');
# Implements a simple preprocessing language.
# Syntax follows two forms. One is the 'line form', which gives you a way to specify arguments inline
# but not spanning multiple lines. The other is 'block form', which gives you access to both one-line
# arguments and a block of lines. The line parameters are passed in verbatim, and the block is
# indentation-adjusted and then passed in as a second parameter. (Indentation is adjusted to align
# with the name of the command.)
#
# Here are the forms:
#
# - line arguments to function
#
# - block line arguments << eof
#   block contents
#   block contents
#   ...
# - eof

my ($string, %options) = @_;
my $expansions         = 0;
my $old_string         = '';
my $limit              = $options{expansion_limit} || 100;
my @pieces             = ();

sub adjust_spaces {
  my ($spaces, $string) = @_;
  $string =~ s/^$spaces  //mg;
  chomp $string;
  $string;
}

while ($old_string ne $string and $expansions++ < $limit) {
  $old_string = $string;

  while ((my @pieces = split  /(^(\h*)-\h \S+ \h* \V* <<\h*(\w+)$ \n .*?  ^\2-\h\3$)/xms, $string) > 1 and $expansions++ < $limit) {
    $pieces[1 + ($_ << 2)] =~ /^ (\h*)-\h(\S+)\h*(\V*)<<\h*(\w+)$ \n(.*?) ^\1-\h\4 $/xms && $externalized_functions{"template::$2"} and
      $pieces[1 + ($_ << 2)] = &{"template::$2"}($3, adjust_spaces($1, $5))
      for 0 .. $#pieces / 4;

    @pieces[2 + ($_ << 2), 3 + ($_ << 2)] = '' for 0 .. $#pieces / 4;
    $string = join '', @pieces;
  }

  if ((my @pieces = split     /^(\h*-\h \S+ \h* .*)$/xom, $string) > 1) {
    $pieces[1 + ($_ << 1)] =~ /^ \h*-\h(\S+)\h*(.*)$/xom && $externalized_functions{"template::$1"} and
      $pieces[1 + ($_ << 1)] = &{"template::$1"}($2)
      for 0 .. $#pieces >> 1;

    $string = join '', @pieces;
  }
}

$string;
__
meta::function('reload', 'around_hook(\'reload\', sub {execute($_) for grep ! /^bootstrap::/, keys %data});');
meta::function('render', <<'__');
hook('before-render');
hook('after-render');
__
meta::function('repl', <<'__');
# Starts a node repl with kevlar already loaded.
node([qw/cached_dependency::caterwaul.js cached_dependency::caterwaul.std.js pp::js::kevlar js::repl-driver/]);

__
meta::function('repl.db', <<'__');
# Starts a node repl with kevlar already loaded.
node([qw/cached_dependency::caterwaul.js cached_dependency::caterwaul.std.js js::kevlar.db js::repl-driver/]);
__
meta::function('rm', <<'__');
around_hook('rm', @_, sub {
  exists $data{$_} or terminal::warning("$_ does not exist") for @_;
  delete @data{@_}});
__
meta::function('run-forever', <<'__');
# Runs your application indefinitely, restarting each time it fails.
# There's a one-second delay between restarts to prevent a tight loop.
# Takes one argument, which is the function to run forever.
my ($f, @args) = @_;
hook('bin/before-run-forever');
&$f(@args) while sleep 0.1 && ! -f 'stop';
hook('bin/after-run-forever');
__
meta::function('save', 'around_hook(\'save\', sub {dangerous(\'\', sub {file::write($0, serialize()); $transient{initial} = state()}) if verify()});');
meta::function('save-state', <<'__');
# Creates a named copy of the current state and stores it.
my ($state_name) = @_;
around_hook('save-state', $state_name, sub {
  associate("state::$state_name", current_state(), execute => 1)});

__
meta::function('sdoc', <<'__');
# Applies SDoc processing to a file or attribute. Takes the file or attribute
# name as the first argument and returns the processed text.

my %comments_for_extension = 
  qw|c     /*,*/  cpp   //    cc   //    h    //    java //  py  #    rb   #    pl  #   pm   #         ml   (*,*)  js  //
     hs    --     sh    #     lisp ;;;   lsp  ;;;   s    ;   scm ;;;  sc   ;;;  as  //  html <!--,-->  mli  (*,*)  cs  //
     vim   "      elisp ;     bas  '     ada  --    asm  ;   awk #    bc   #    boo #   tex  %         fss  (*,*)  erl %
     scala //     hx    //    io   //    j    NB.   lua  --  n   //   m    %    php //  sql  --        pov  //     pro %
     r     #      self  ","   tcl  #     texi @c    tk   #   csh #    vala //   vbs '   v    /*,*/     vhdl --     ss  ;;;
     haml  -#     sass  /*,*/ scss /*,*/ css  /*,*/ fig  /|;

# No extension suggests a shebang line, which generally requires # to denote a comment.
$comments_for_extension{''} = '#';

my $generated_string = 'Generated by SDoc';

sub is_code    {map /^\s*[^A-Z\|\s]/o, @_}
sub is_blank   {map /^\n/o, @_}
sub comment    {my ($text, $s, $e) = @_; join "\n", map("$s $_$e", split /\n/, $text)}

sub paragraphs {map split(/(\n{2,})/, $_), @_}

my ($filename) = @_;

# Two possibilities here. One is that the filename is an attribute, in which case
# we want to look up the extension in the transients table. The other is that
# it's a real filename.
my ($extension)       = $filename =~ /\.sdoc$/io ? $filename =~ /\.(\w+)\.sdoc$/igo : $filename =~ /\.(\w+)$/igo;
my ($other_extension) = extension_for(attribute($filename));
$other_extension =~ s/^\.//o;

my ($start, $end) = split /,/o, $comments_for_extension{lc($other_extension || $extension)};

join '', map(is_code($_) || is_blank($_) ? ($_ =~ /^\s*c\n(.*)$/so ? $1 : $_) : comment($_, $start, $end), paragraphs retrieve($filename)),
         "\n$start $generated_string $end\n";
__
meta::function('sdoc-html', <<'__');
# Converts SDoc to logically-structured HTML. Sections end up being nested,
# and code sections and examples are marked as such. For instance, here is some
# sample output:

# <div class='section level1'>
#   <h1 class='title'>Foo</h1>
#   <p>This is a paragraph...</p>
#   <p>This is another paragraph...</p>
#   <pre class='code'>int main () {return 0;}</pre>
#   <pre class='quoted'>int main () {return 0} // Won't compile</pre>
#   <div class='section level2'>
#     <h2 class='title'>Bar</h2>
#     ...
#   </div>
# </div>

# It is generally good about escaping things that would interfere with HTML,
# but within text paragraphs it lets you write literal HTML. The heuristic is
# that known tags that are reasonably well-formed are allowed, but unknown ones
# are escaped.

my ($attribute)   = @_;
my @paragraphs    = split /\n(?:\s*\n)+/, retrieve($attribute);

my $known_tags    = join '|', qw[html head body meta script style link title div a span input button textarea option select form label iframe blockquote code caption
                                 table tbody tr td th thead tfoot img h1 h2 h3 h4 h5 h6 li ol ul noscript p pre samp sub sup var canvas audio video];
my $section_level = 0;
my @markup;

my $indent        = sub {'  ' x ($_[0] || $section_level)};
my $unindent      = sub {my $spaces = '  ' x ($section_level - 1); s/^$spaces//gm};

my $escape_all    = sub {s/&/&amp;/g; s/</&lt;/g; s/>/&gt;/g};
my $escape_some   = sub {s/&/&amp;/g; s/<(?!\/|($known_tags)[^>]*>.*<\/\1>)/&lt;/gs};

my $code          = sub {&$escape_all(); &$unindent(); s/^c\n//;                   push @markup, &$indent() . "<pre class='code'>$_</pre>"};
my $quoted        = sub {&$escape_all(); &$unindent(); s/^\|(\s?)/ \1/; s/^  //mg; push @markup, &$indent() . "<pre class='quoted'>$_</pre>"};

my $paragraph     = sub {&$escape_some(); push @markup, &$indent() . "<p>$_</p>"};

my $section       = sub {my $h = $_[0] > 6 ? 6 : $_[0]; push @markup, &$indent($_[0] - 1) . "<div class='section level$_[0]'>", &$indent($_[0]) . "<h$h>$2</h$h>"};
my $close_section = sub {push @markup, &$indent($_[0]) . "</div>"};

my $title = sub {
  my $indentation = (length($1) >> 1) + 1;
  &$close_section($section_level) while $section_level-- >= $indentation;
  &$section($indentation);
  $section_level = $indentation;
};

for (@paragraphs) {
  &$code(),   next unless /^\h*[A-Z|]/;
  &$quoted(), next if     /^\h*\|/;

  &$title(), s/^.*\n// if /^(\s*)(\S.*)\.\n([^\n]+)/ and length("$1$2") - 10 < length($3);
  &$paragraph();
}

&$close_section($section_level) while $section_level--;

join "\n", @markup;
__
meta::function('sdocp', <<'__');
# Renders an attribute as SDocP. This logic was taken directly from the sdoc script.
my $attribute = retrieve($_[0]);
sub escape {my @results = map {s/\\/\\\\/go; s/\n/\\n/go; s/'/\\'/go; $_} @_; wantarray ? @results : $results[0]}
"sdocp('" . escape($_[0]) . "', '" . escape($attribute) . "');";
__
meta::function('serialize', <<'__');
my ($options, @criteria) = separate_options(@_);
my $partial     = $$options{'-p'};
my $criteria    = join '|', @criteria;
my @attributes  = map serialize_single($_), select_keys(%$options, '-m' => 1, '--criteria' => $criteria), select_keys(%$options, '-M' => 1, '--criteria' => $criteria);
my @final_array = @{$partial ? \@attributes : [retrieve('bootstrap::initialization'), @attributes, 'internal::main();', '', '__END__']};
join "\n", @final_array;
__
meta::function('serialize-single', <<'__');
# Serializes a single attribute and optimizes for content.

my $name          = $_[0] || $_;
my $contents      = $data{$name};
my $meta_function = 'meta::' . namespace($name);
my $invocation    = attribute($name);
my $escaped       = $contents;
$escaped =~ s/\\/\\\\/go;
$escaped =~ s/'/\\'/go;

return "$meta_function('$invocation', '$escaped');" unless $escaped =~ /\v/;

my $delimiter = '__' . fast_hash($contents);
my $chars     = 2;

++$chars until $chars >= length($delimiter) || index("\n$contents", "\n" . substr($delimiter, 0, $chars)) == -1;
$delimiter = substr($delimiter, 0, $chars);

"$meta_function('$invocation', <<'$delimiter');\n$contents\n$delimiter";
__
meta::function('sh', 'system(@_);');
meta::function('shb', <<'__');
# Backgrounded shell job.
exec(@_) unless fork;

__
meta::function('shell', <<'__');
terminal::cc(retrieve('data::current-continuation')) if length $data{'data::current-continuation'};
around_hook('shell', sub {shell::repl()});

__
meta::function('size', <<'__');
my $size = 0;
$size += length $data{$_} for keys %data;
sprintf "% 7d % 7d", length(serialize()), $size;
__
meta::function('snapshot', <<'__');
my ($name) = @_;
file::write(my $finalname = temporary_name($name), serialize(), noclobber => 1);
chmod 0700, $finalname;
hook('snapshot', $finalname);
__
meta::function('state', <<'__');
my @keys = sort keys %data;
my $hash = fast_hash(fast_hash(scalar @keys) . join '|', @keys);
$hash = fast_hash("$data{$_}|$hash") for @keys;
$hash;
__
meta::function('todo-summary', <<'__');
my @todo_items = &{'parse-todo'}(@_);
my %categories;
my %category_completion;

push @{$categories{$_->{category}} ||= []}, $_         for @todo_items;
$category_completion{$_->{category}} += $_->{progress} for @todo_items;

# Adjust to represent averages rather than totals
$category_completion{$_} /= @{$categories{$_}} for keys %categories;

join "\n\n", map sprintf("%s: %4.2f%%\n%s", $_, $category_completion{$_} * 100,
                         join "\n", map sprintf("%-8s %s", "[$_->{progress_meter}]", $_->{details}), @{$categories{$_}}), sort keys %categories;

__
meta::function('touch', 'associate($_, \'\') for @_;');
meta::function('unlock', 'hook(\'unlock\', chmod_self(sub {$_[0] | 0200}));');
meta::function('update', <<'__');
update_from(@_, grep s/^parent:://o, sort keys %data);

__
meta::function('update-from', <<'__');
# Upgrade all attributes that aren't customized. Customization is defined when the data type is created,
# and we determine it here by checking for $transient{inherit}{$type}.

# Note that this assumes you trust the remote script. If you don't, then you shouldn't update from it.

around_hook('update-from-invocation', separate_options(@_), sub {
  my ($options, @targets) = @_;
  my %parent_id_cache = cache('parent-identification');
  my %already_seen;

  @targets or return;

  my @known_targets     = grep s/^parent:://, parent_ordering(map "parent::$_", grep exists $data{"parent::$_"}, @targets);
  my @unknown_targets   = grep ! exists $data{"parent::$_"}, @targets;
  @targets = (@known_targets, @unknown_targets);

  my $save_state        = ! ($$options{'-n'} || $$options{'--no-save'});
  my $no_parents        =    $$options{'-P'} || $$options{'--no-parent'} || $$options{'--no-parents'};
  my $force             =    $$options{'-f'} || $$options{'--force'};
  my $clobber_divergent =    $$options{'-D'} || $$options{'--clobber-divergent'};

  save_state('before-update') if $save_state;

  for my $target (@targets) {
    dangerous("updating from $target", sub {
    around_hook('update-from', $target, sub {
      my $identity = $parent_id_cache{$target} ||= join '', qx($target identity);
      next if $already_seen{$identity};
      $already_seen{$identity} = 1;

      my $attributes = join '', qx($target ls -ahiu);
      my %divergent;
      die "skipping unreachable $target" unless $attributes;

      for my $to_rm (split /\n/, retrieve("parent::$target")) {
        my ($name, $hash) = split(/\s+/, $to_rm);
        next unless exists $data{$name};

        my $local_hash = fast_hash(retrieve($name));
        if ($clobber_divergent or $hash eq $local_hash or ! defined $hash) {rm($name)}
        else {terminal::info("preserving local version of divergent attribute $name (use update -D to clobber it)");
              $divergent{$name} = retrieve($name)}}

      associate("parent::$target", $attributes) unless $no_parents;

      dangerous('', sub {eval qx($target serialize -ipmu)});
      dangerous('', sub {eval qx($target serialize -ipMu)});

      map associate($_, $divergent{$_}), keys %divergent unless $clobber_divergent;

      reload()})})}

  cache('parent-identification', %parent_id_cache);

  if (verify()) {hook('update-from-succeeded', $options, @targets);
                 terminal::info("Successfully updated. Run 'load-state before-update' to undo this change.") if $save_state}
  elsif ($force) {hook('update-from-failed', $options, @targets);
                  terminal::warning('Failed to verify: at this point your object will not save properly, though backup copies will be created.',
                                    'Run "load-state before-update" to undo the update and return to a working state.') if $save_state}
  else {hook('update-from-failed', $options, @targets);
        terminal::error('Verification failed after the upgrade was complete.');
        terminal::info("$0 has been reverted to its pre-upgrade state.", "If you want to upgrade and keep the failure state, then run 'update-from $target --force'.") if $save_state;
        return load_state('before-update') if $save_state}});

__
meta::function('usage', '"Usage: $0 action [arguments]\\nUnique actions (run \'$0 ls\' to see all actions):" . ls(\'-u\');');
meta::function('verify', <<'__');
file::write(my $other = $transient{temporary_filename} = temporary_name(), my $serialized_data = serialize());
chomp(my $observed = join '', qx|perl '$other' state|);

unlink $other if my $result = $observed eq (my $state = state());
terminal::error("Verification failed; expected $state but got $observed from $other") unless $result;
hook('after-verify', $result, observed => $observed, expected => $state);
$result;
__
meta::function('vim', <<'__');
# Installs VIM highlighters.
file::write("$ENV{'HOME'}/.vim/syntax/$_.vim", retrieve("vim_highlighter::$_")) for grep s/^vim_highlighter:://o, keys %data;
__
meta::hook('after-render::base-files', <<'__');
file::write('kevlar.client.jquery.js',    retrieve('pp::js::kevlar.client.jquery'));
file::write('kevlar.client.transport.js', retrieve('pp::js::kevlar.transport'));
file::write('kevlar.js',                  retrieve('pp::js::kevlar'));

__
meta::indicator('cc', 'length ::retrieve(\'data::current-continuation\') ? "\\033[1;36mcc\\033[0;0m" : \'\';');
meta::indicator('locked', 'is_locked() ? "\\033[1;31mlocked\\033[0;0m" : \'\';');
meta::indicator('state', <<'__');
my $state = $options{state} // state();
my $color = $state ne $transient{initial} ? 33 : 30;
"\033[1;${color}m" . substr($state, 0, 4) . "\033[0;0m";
__
meta::internal_function('around_hook', <<'__');
# around_hook('hookname', @args, sub {
#   stuff;
# });

# Invokes 'before-hookname' on @args before the sub runs, invokes the
# sub on @args, then invokes 'after-hookname' on @args afterwards.
# The after-hook is not invoked if the sub calls 'die' or otherwise
# unwinds the stack.

my $hook = shift @_;
my $f    = pop @_;

hook("before-$hook", @_);
my $result = &$f(@_);
hook("after-$hook", @_);
$result;
__
meta::internal_function('associate', <<'__');
my ($name, $value, %options) = @_;
die "Namespace does not exist" unless exists $datatypes{namespace($name)};
$data{$name} = $value;
execute($name) if $options{'execute'};
$value;
__
meta::internal_function('attribute', <<'__');
my ($name) = @_;
$name =~ s/^[^:]*:://;
$name;
__
meta::internal_function('attribute_is', <<'__');
my ($a, %options) = @_;
my %inherited     = parent_attributes(grep /^parent::/o, sort keys %data) if grep exists $options{$_}, qw/-u -U -d -D/;
my $criteria      = $options{'--criteria'} || $options{'--namespace'} && "^$options{'--namespace'}::" || '.';

my %tests = ('-u' => sub {! $inherited{$a}},
             '-d' => sub {$inherited{$a} && fast_hash(retrieve($a)) ne $inherited{$a}},
             '-i' => sub {$transient{inherit}{namespace($a)}},
             '-s' => sub {$a =~ /^state::/o},
             '-m' => sub {$a =~ /^meta::/o});

return 0 unless scalar keys %tests == scalar grep ! exists $options{$_}    ||   &{$tests{$_}}(), keys %tests;
return 0 unless scalar keys %tests == scalar grep ! exists $options{uc $_} || ! &{$tests{$_}}(), keys %tests;
$a =~ /$criteria/
__
meta::internal_function('cache', <<'__');
my ($name, %pairs) = @_;
if (%pairs) {associate("cache::$name", join "\n", map {$pairs{$_} =~ s/\n//g; "$_ $pairs{$_}"} sort keys %pairs)}
else        {map split(/\s/, $_, 2), split /\n/, retrieve("cache::$name")}
__
meta::internal_function('chmod_self', <<'__');
my ($mode_function)      = @_;
my (undef, undef, $mode) = stat $0;
chmod &$mode_function($mode), $0;
__
meta::internal_function('dangerous', <<'__');
# Wraps a computation that may produce an error.
my ($message, $computation) = @_;
terminal::info($message) if $message;
my @result = eval {&$computation()};
terminal::warning(translate_backtrace($@)), return undef if $@;
wantarray ? @result : $result[0];
__
meta::internal_function('debug_trace', <<'__');
terminal::debug(join ', ', @_);
wantarray ? @_ : $_[0];
__
meta::internal_function('dep', <<'__');
# A variadic function to prepend cached_dependency:: onto things.
# Used like this: dep(qw/caterwaul.all.js montenegro.server.js/)
map "cached_dependency::$_", @_;
__
meta::internal_function('execute', <<'__');
my ($name, %options) = @_;
my $namespace = namespace($name);
eval {&{$datatypes{$namespace}}(attribute($name), retrieve($name))};
warn $@ if $@ && $options{'carp'};

__
meta::internal_function('exported', <<'__');
# Allocates a temporary file containing the concatenation of attributes you specify,
# and returns the filename. The filename will be safe for deletion anytime.
my $filename = temporary_name();
file::write($filename, cat(@_));
$filename;
__
meta::internal_function('extension_for', <<'__');
my $extension = $transient{extension}{namespace($_[0])};
$extension = &$extension($_[0]) if ref $extension eq 'CODE';
$extension || '';
__
meta::internal_function('fast_hash', <<'__');
my ($data)     = @_;
my $piece_size = length($data) >> 3;

my @pieces     = (substr($data, $piece_size * 8) . length($data), map(substr($data, $piece_size * $_, $piece_size), 0 .. 7));
my @hashes     = (fnv_hash($pieces[0]));

push @hashes, fnv_hash($pieces[$_ + 1] . $hashes[$_]) for 0 .. 7;

$hashes[$_] ^= $hashes[$_ + 4] >> 16 | ($hashes[$_ + 4] & 0xffff) << 16 for 0 .. 3;
$hashes[0]  ^= $hashes[8];

sprintf '%08x' x 4, @hashes[0 .. 3];
__
meta::internal_function('file::read', <<'__');
my $name = shift;
open my($handle), "<", $name;
my $result = join "", <$handle>;
close $handle;
$result;
__
meta::internal_function('file::write', <<'__');
use File::Path     'mkpath';
use File::Basename 'dirname';

my ($name, $contents, %options) = @_;
die "Choosing not to overwrite file $name" if $options{noclobber} and -f $name;
mkpath(dirname($name)) if $options{mkpath};

open my($handle), $options{append} ? '>>' : '>', $name or die "Can't open $name for writing";
print $handle $contents;
close $handle;
__
meta::internal_function('fnv_hash', <<'__');
# A rough approximation to the Fowler-No Voll hash. It's been 32-bit vectorized
# for efficiency, which may compromise its effectiveness for short strings.

my ($data) = @_;

my ($fnv_prime, $fnv_offset) = (16777619, 2166136261);
my $hash                     = $fnv_offset;
my $modulus                  = 2 ** 32;

$hash = ($hash ^ ($_ & 0xffff) ^ ($_ >> 16)) * $fnv_prime % $modulus for unpack 'L*', $data . substr($data, -4) x 8;
$hash;
__
meta::internal_function('hypothetically', <<'__');
# Applies a temporary state and returns a serialized representation.
# The original state is restored after this, regardless of whether the
# temporary state was successful.

my %data_backup   = %data;
my ($side_effect) = @_;
my $return_value  = eval {&$side_effect()};
%data = %data_backup;

die $@ if $@;
$return_value;
__
meta::internal_function('internal::main', <<'__');
disable();

$SIG{'INT'} = sub {snapshot(); exit 1};

$transient{initial}      = state();
chomp(my $default_action = retrieve('data::default-action'));

my $function_name = shift(@ARGV) || $default_action || 'usage';
terminal::warning("unknown action: '$function_name'") and $function_name = 'usage' unless $externalized_functions{$function_name};

around_hook('main-function', $function_name, @ARGV, sub {
  dangerous('', sub {
    chomp(my $result = &$function_name(@ARGV));
    print "$result\n" if $result})});

save() unless state() eq $transient{initial};

END {
  enable();
}
__
meta::internal_function('invoke_editor_on', <<'__');
my ($data, %options) = @_;
my $editor    = $options{editor} || $ENV{VISUAL} || $ENV{EDITOR} || die 'Either the $VISUAL or $EDITOR environment variable should be set to a valid editor';
my $options   = $options{options} || $ENV{VISUAL_OPTS} || $ENV{EDITOR_OPTS} || '';
my $attribute = $options{attribute};
$attribute =~ s/\//-/g;
my $filename  = temporary_name() . "-$attribute$options{extension}";

file::write($filename, $data);
system("$editor $options '$filename'");

my $result = file::read($filename);
unlink $filename;
$result;
__
meta::internal_function('is_locked', '!((stat($0))[2] & 0222);');
meta::internal_function('namespace', <<'__');
my ($name) = @_;
$name =~ s/::.*$//;
$name;
__
meta::internal_function('parent_attributes', <<'__');
my $attributes = sub {my ($name, $value) = split /\s+/o, $_; $name => ($value || 1)};
map &$attributes(), split /\n/o, join("\n", retrieve(@_));
__
meta::internal_function('parent_ordering', <<'__');
# Topsorts the parents by dependency chain. The simplest way to do this is to
# transitively compute the number of parents referred to by each parent.

my @parents = @_;
my %all_parents = map {$_ => 1} @parents;

my %parents_of = map {
  my $t = $_;
  my %attributes = parent_attributes($_);
  $t => [grep /^parent::/, keys %attributes]} @parents;

my %parent_count;
my $parent_count;
$parent_count = sub {
  my ($key) = @_;
  return $parent_count{$key} if exists $parent_count{$key};
  my $count = 0;
  $count += $parent_count->($_) + exists $data{$_} for @{$parents_of{$key}};
  $parent_count{$key} = $count};

my %inverses;
push @{$inverses{$parent_count->($_)} ||= []}, $_ for @parents;
grep exists $all_parents{$_}, map @{$inverses{$_}}, sort keys %inverses;
__
meta::internal_function('retrieve', <<'__');
my @results = map defined $data{$_} ? $data{$_} : retrieve_with_hooks($_), @_;
wantarray ? @results : $results[0];
__
meta::internal_function('retrieve_with_hooks', <<'__');
# Uses the hooks defined in $transient{retrievers}, and returns undef if none work.
my ($attribute) = @_;
my $result      = undef;

defined($result = &$_($attribute)) and return $result for map $transient{retrievers}{$_}, sort keys %{$transient{retrievers}};
return undef;
__
meta::internal_function('select_keys', <<'__');
my %options = @_;
grep attribute_is($_, %options), sort keys %data;
__
meta::internal_function('separate_options', <<'__');
# Things with one dash are short-form options, two dashes are long-form.
# Characters after short-form are combined; so -auv4 becomes -a -u -v -4.
# Also finds equivalences; so --foo=bar separates into $$options{'--foo'} eq 'bar'.
# Stops processing at the -- option, and removes it. Everything after that
# is considered to be an 'other' argument.

# The only form not supported by this function is the short-form with argument.
# To pass keyed arguments, you need to use long-form options.

my @parseable;
push @parseable, shift @_ until ! @_ or $_[0] eq '--';

my @singles = grep /^-[^-]/, @parseable;
my @longs   = grep /^--/,    @parseable;
my @others  = grep ! /^-/,   @parseable;

my @singles = map /-(.{2,})/ ? map("-$_", split(//, $1)) : $_, @singles;

my %options;
  $options{$1} = $2 for grep /^([^=]+)=(.*)$/, @longs;
++$options{$_}      for grep ! /=/, @singles, @longs;

({%options}, @others, @_);
__
meta::internal_function('strip', 'wantarray ? map {s/^\\s*|\\s*$//g; $_} @_ : $_[0] =~ /^\\s*(.*?)\\s*$/ && $1;');
meta::internal_function('table_display', <<'__');
# Displays an array of arrays as a table; that is, with alignment. Arrays are
# expected to be in column-major order.

sub maximum_length_in {
  my $maximum = 0;
  length > $maximum and $maximum = length for @_;
  $maximum;
}

my @arrays    = @_;
my @lengths   = map maximum_length_in(@$_), @arrays;
my @row_major = map {my $i = $_; [map $$_[$i], @arrays]} 0 .. $#{$arrays[0]};
my $format    = join '  ', map "%-${_}s", @lengths;

join "\n", map strip(sprintf($format, @$_)), @row_major;
__
meta::internal_function('temporary_name', <<'__');
use File::Temp 'tempfile';
my (undef, $temporary_filename) = tempfile("$0." . 'X' x 4, OPEN => 0);
$temporary_filename;
__
meta::internal_function('translate_backtrace', <<'__');
my ($trace) = @_;
$trace =~ s/\(eval (\d+)\)/$locations{$1 - 1}/g;
$trace;
__
meta::internal_function('with_exported', <<'__');
# Like exported(), but removes the file after running some function.
# Usage is with_exported(@files, sub {...});
my $f      = pop @_;
my $name   = exported(@_);
my $result = eval {&$f($name)};
terminal::warning("$@ when running with_exported()") if $@;
unlink $name;
$result;
__
meta::js('repl-driver', <<'__');
var repl = require('repl').start();
repl.context.kevlar = kevlar;

__
meta::library('shell', <<'__');
# Functions for shell parsing and execution.
package shell;
use Term::ReadLine;

sub tokenize {grep length, split /\s+|("[^"\\]*(?:\\.)?")/o, join ' ', @_};

sub parse {
  my ($fn, @args) = @_;
  s/^"(.*)"$/\1/o, s/\\\\"/"/go for @args;
  {function => $fn, args => [@args]}}

sub execute {
  my %command = %{$_[0]};
  die "undefined command: $command{function}" unless exists $externalized_functions{$command{function}};
  &{"::$command{function}"}(@{$command{args}})}

sub run {execute(parse(tokenize(@_)))}

sub prompt {
  my %options = @_;
  my $name    = $options{name} // ::name();

  my $indicators = join '', map &{"::$_"}(), ::select_keys('--namespace' => 'indicator');

  "\033[1;32m$name\033[0;0m$indicators "}

sub repl {
  my %options = @_;

  my $term = new Term::ReadLine "$0 shell";
  $term->ornaments(0);
  my $attribs = $term->Attribs;
  $attribs->{completion_entry_function} = $attribs->{list_completion_function};

  my $autocomplete = $options{autocomplete} || sub {[sort keys %data, sort keys %externalized_functions]};
  my $prompt       = $options{prompt}       || \&prompt;
  my $parse        = $options{parse}        || sub {parse(tokenize(@_))};
  my $command      = $options{command}      || sub {my ($command) = @_; ::around_hook('shell-command', $command, sub {print ::dangerous('', sub {execute($command)}), "\n"})};

  length $_ && &$command(&$parse($_)) while ($attribs->{completion_word} = &$autocomplete(), defined($_ = $term->readline(&$prompt())))}

__
meta::library('terminal', <<'__');
# Functions for nice-looking terminal output.
package terminal;

my $process = ::name();

sub message {print STDERR "[$_[0]] $_[1]\n"}
sub color {
  my ($name, $color) = @_;
  *{"terminal::$name"} = sub {chomp($_), print STDERR "\033[1;30m$process(\033[1;${color}m$name\033[1;30m)\033[0;0m $_\n" for map join('', $_), @_}}

my %preloaded = (info => 32, progress => 32, state => 34, debug => 34, warning => 33, error => 31);
color $_, $preloaded{$_} for keys %preloaded;
__
meta::message_color('cc', '36');
meta::message_color('state', 'purple');
meta::message_color('states', 'yellow');
meta::message_color('test', 'purple');
meta::parent('./sdoc', <<'__');
function::sdoc                           4d33dcf625897e463bb30fc91cb94339
function::sdoc-html                      7e7de47fe059a336309a4a0c06856401
function::sdocp                          c3d738d982ba87418a298ff58478a85b
meta::type::sdoc                         22cd7315641d38c9d536344e83c36bed
parent::/home/spencertipping/bin/object  1ac66054532268622a9faa98082ee254
retriever::html-sdoc                     2a5d5aa45e2d7576f79e045177d8705c
retriever::sdoc                          662061e9e41491e2a1debd6862ccf1e7
retriever::sdocp                         330694ea14a23bb04b65c761075cd946

__
meta::parent('/home/spencertipping/bin/configuration', <<'__');
meta::type::configuration                7f5ba514d47ac29a3c226d0e331d9da4
parent::/home/spencertipping/bin/object  1ac66054532268622a9faa98082ee254

__
meta::parent('/home/spencertipping/bin/node-base', <<'__');
function::loc                                               6b2be2b7f7a9c0f524c3a6e9fad3daa3
function::node                                              b0b71c40082dadf3ed4d8510534ff5cc
function::node-custom                                       9ebcf90e9a7bb24e7611b98ae49e90fc
function::render                                            48667802c456d49fdf63836f7994dfa7
function::run-forever                                       e5b227e835b00b82d439dc24a1873622
internal_function::dep                                      9f5c8b82af8796a0ef9909de9c28d56b
message_color::test                                         03621cd6ac0b1a40d703f41e26c5807f
meta::type::js                                              e292996c992f4bc110e9577266c94784
parent::/home/spencertipping/bin/repository                 0fe3f55c8cd08b6895126f9944027fc6
parent::/home/spencertipping/conjectures/perl-objects/sdoc  cf30ed24cbd679b96e608a6c67dae069
parent::notes                                               52e9dde4eef92e36cc2ba8ad9f51123e
parent::preprocessor                                        d5f9081e9a9a0b5e737ceee08f5ce507

__
meta::parent('/home/spencertipping/bin/object', <<'__');
bootstrap::html                         f44dd03cb0c904b3a5f69fbda5f018d0
bootstrap::initialization               7637e32ba308624d824eacc9337c2512
bootstrap::perldoc                      5793df44bdd2526bb461272924abfd4b
function::alias                         fb63bb3836ab968de2ee93f33d1704ec
function::cat                           f684de6c8776617a437b76009114f52e
function::cc                            12ea9176e388400704d823433c209b7a
function::ccc                           d151a9793edd83f80fb880b7f0ab9b34
function::child                         f5764adf0b4e892f147a9b6b68d4816f
function::clone                         bb42e04e10a8e54e88786b6fbc4fb213
function::cp                            3fe69d1b58d90045ad520048977538c4
function::create                        3010d55f4dfa59a998742e07823ed54d
function::current-state                 6f03f86f1901e9ef07fdb5d4079a914c
function::disable                       53b449708cc2ffdefa352e53bb7d847d
function::edit                          9ce5ba1ae4607e8cf1975080bcde1cf4
function::enable                        7de1cedc36841f5de8f9fdfbc3b65097
function::export                        2374cd1dbf7616cb38cafba4e171075d
function::extern                        1290a5223e2824763eecfb3a54961eff
function::grep                          55c3cea8ff4ec2403be2a9d948e59f14
function::hash                          6ee131d093e95b80039b4df9c7c84a02
function::hook                          675cdb98b5dd8567bdd5a02ead6184b5
function::hooks                         3d989899c616f7440429a2d9bf1cc44b
function::identity                      6523885762fcc2f354fc25cf6ed126ce
function::import                        5d0f0634cbd01274f2237717507198a2
function::initial-state                 03d8ed608855a723124e79ca184d8e73
function::is                            41564c8f21b12ab80824ac825266d805
function::load-state                    b6cf278a1f351f316fa6e070359b6081
function::lock                          5d8db258704e6a8623fac796f62fac02
function::ls                            0b310755e747c65bca09508fd9d841f0
function::mv                            4a0e338a6edb89ad1e2c779d51d4d47b
function::name                          955ba2d1fe1d67cd78651a4042283b00
function::parents                       3da9e63b5aae9e2f5dcc946a86d166aa
function::perl                          a0f341ea54391b63b6195e7992b6a686
function::reload                        1589f4cf8374e0011991cb8907afca3e
function::rm                            6f6fd7a6c25558eb469d78ea888f8551
function::save                          778c0e1043b9c6c96fb8f266f8061624
function::save-state                    5af59ebc4ad8965767e4dc106d3b557e
function::serialize                     a19ada2d2558ea9da3a7942fb913e15f
function::serialize-single              aa77af032272f5a2664e21713739a223
function::sh                            1b2f542ca9dd63ad437058b7f6f61aac
function::shb                           7b2685a4041c25bc495816e472bdace5
function::shell                         22d25a32ffc3f2855fb7e2aec77c72fb
function::size                          6cd9a4dd17be87ea2962f8f566a97d11
function::snapshot                      56939a47f2758421669641e15ebd66eb
function::state                         8c68044dccae28f33244d0c7e9e9acfb
function::touch                         3991b1b7c7187566f50e5e58ce01fa06
function::unlock                        b4aac02f7f3fb700acf4acfd9b180ceb
function::update                        ac391dc90e507e7586c81850e7c2ecdd
function::update-from                   631721c4dc30e11b2023a6703cbcef52
function::usage                         5bdd370f5a56cfbf199e08d398091444
function::verify                        0c0cc1dfeab7d705919df122f7850a4f
indicator::cc                           3db7509c521ee6abfedd33d5f0148ed3
indicator::locked                       fc2b4f4ca0d6a334b9ac423d06c8f18c
indicator::state                        7c9d42b8fcee852a80d61c4f119c1239
internal_function::around_hook          7cc876e7c5f78c34654337fc95255587
internal_function::associate            05a75afb70daee635eefec8ae037f593
internal_function::attribute            dd6f010f9688977464783f60f5b6d3dd
internal_function::attribute_is         a33841586c7a83264ba2116937d1c5b6
internal_function::cache                eb9da45580a9ac0882baf98acd2ecd60
internal_function::chmod_self           2035e861eedab55ba0a9f6f5a068ca70
internal_function::dangerous            46c4baaa214ab3d05af43e28083d5141
internal_function::debug_trace          0faf9d9f4159d72dfe4481f6f3607ce1
internal_function::execute              f0924e087d978ff2ab1e117124db3042
internal_function::exported             3ec48f01deefa840b52111f2e3f34749
internal_function::extension_for        9de8261d69cc93e9b92072b89c89befd
internal_function::fast_hash            ee5eba48f837fda0fe472645fdd8899a
internal_function::file::read           e647752332c8e05e81646a3ff98f9a8e
internal_function::file::write          3e290fdcb353c6f842eb5a40f2e575f8
internal_function::fnv_hash             c36d56f1e13a60ae427afc43ba025afc
internal_function::hypothetically       b83e3f894a6df8623ccd370515dfd976
internal_function::internal::main       f31f2945a19a668d92505f114ab29c78
internal_function::invoke_editor_on     5eb976796f0ec172d6ec036116a2f41e
internal_function::is_locked            da12ced6aa38295251f7e748ffd22925
internal_function::namespace            784d2e96003550681a4ae02b8d6d0a27
internal_function::parent_attributes    f6ccfaa982ab1a4d066043981aaca277
internal_function::parent_ordering      57b6da88f76b59f3fed9abfa61280e5e
internal_function::retrieve             8a34d1fe047fe1b40c3d2957c4a789eb
internal_function::retrieve_with_hooks  0f1b0220ccd973d57a2e96ff00458cf2
internal_function::select_keys          a5e3532ec6d58151d0ee24416ea1e2b5
internal_function::separate_options     da1c2a3a1e03faafe6b4446ebb6bad90
internal_function::strip                14f490b10ebd519e829d8ae20ea4d536
internal_function::table_display        d575f4dc873b2e0be5bd7352047fd904
internal_function::temporary_name       6f548d101fc68356515ffd0fc9ae0c93
internal_function::translate_backtrace  d77a56d608473b3cd8a3c6cb84185e10
internal_function::with_exported        df345d5095d5ed13328ddd07ea922b36
library::shell                          378715d20a4a87ee305dd2c3cff1b588
library::terminal                       7e2d045782405934a9614fe04bcfe559
message_color::cc                       2218ef0f7425de5c717762ffb100eb43
message_color::state                    03621cd6ac0b1a40d703f41e26c5807f
message_color::states                   ac66eeeff487b5f43f88a78ea18b3d56
meta::configure                         69c2e727c124521d074fde21f8bbc4db
meta::externalize                       aa44e27e0bbee6f0ca4de25d603a1fc7
meta::functor::editable                 48246c608f363de66511400e00b26164
meta::type::alias                       889d26d2df385e9ff8e2da7de4e48374
meta::type::bootstrap                   51108ab2ddb8d966e927c8f62d9ef3e5
meta::type::cache                       9267171f2eace476f64a1a670eaaf2c7
meta::type::data                        120e1649a468d3b3fd3fb783b4168499
meta::type::function                    8ea626198861dc59dd7f303eecb5ff88
meta::type::hook                        ff92aef328b6bdc6f87ddd0821f3e42f
meta::type::inc                         78e0375b6725487cb1f0deca41e96bbe
meta::type::indicator                   feb54a2624e6983617685047c717427f
meta::type::internal_function           eff3cf31e2635f51c83836f116c99d2f
meta::type::library                     7622e8d65e03066668bade74715d65ad
meta::type::message_color               557a1b44979cbf77a7251fbdc4c5b82c
meta::type::meta                        c6250056816b58a9608dd1b2614246f8
meta::type::parent                      09d1d03379e4e0b262e06939f4e00464
meta::type::retriever                   71a29050bf9f20f6c71afddff83addc9
meta::type::state                       84da7d5220471307f1f990c5057d3319
retriever::file                         3bbc9d8a887a536044bafff1d54def7e
retriever::id                           4da6080168d32445150cc4200af7af6e
retriever::object                       c7633990b4e01bdc783da7e545799f4f
retriever::perl                         f41938e6dbad317f62abffc1e4d28cca

__
meta::parent('/home/spencertipping/bin/repository', <<'__');
function::dupdate                               3203750417390913ae3892002b53bdc1
meta::type::cached_dependency                   b9dc0b20c2d3af0deb3b835b20cac4a7
parent::/home/spencertipping/bin/configuration  5baec3ad75737e776a1d1b27021d2d01
retriever::http                                 a23617a5787de41d1a89ad4496cacce3

__
meta::parent('/home/spencertipping/conjectures/perl-objects/sdoc', <<'__');
function::sdoc                           4d33dcf625897e463bb30fc91cb94339
function::sdoc-html                      7e7de47fe059a336309a4a0c06856401
function::sdocp                          c3d738d982ba87418a298ff58478a85b
meta::type::sdoc                         22cd7315641d38c9d536344e83c36bed
parent::/home/spencertipping/bin/object  1ac66054532268622a9faa98082ee254
retriever::html-sdoc                     2a5d5aa45e2d7576f79e045177d8705c
retriever::sdoc                          662061e9e41491e2a1debd6862ccf1e7
retriever::sdocp                         330694ea14a23bb04b65c761075cd946

__
meta::parent('notes', <<'__');
function::note    5e2737593e8d13fc43bb10e97603e53a
function::notes   7229b326ac8686b2db6de98496bc7527
meta::type::note  f81bea58841a438e4ee34608ab4f54c0
parent::object    1ac66054532268622a9faa98082ee254

__
meta::parent('object', <<'__');
bootstrap::html                         f44dd03cb0c904b3a5f69fbda5f018d0
bootstrap::initialization               7637e32ba308624d824eacc9337c2512
bootstrap::perldoc                      5793df44bdd2526bb461272924abfd4b
function::alias                         fb63bb3836ab968de2ee93f33d1704ec
function::cat                           f684de6c8776617a437b76009114f52e
function::cc                            12ea9176e388400704d823433c209b7a
function::ccc                           d151a9793edd83f80fb880b7f0ab9b34
function::child                         f5764adf0b4e892f147a9b6b68d4816f
function::clone                         bb42e04e10a8e54e88786b6fbc4fb213
function::cp                            3fe69d1b58d90045ad520048977538c4
function::create                        3010d55f4dfa59a998742e07823ed54d
function::current-state                 6f03f86f1901e9ef07fdb5d4079a914c
function::disable                       53b449708cc2ffdefa352e53bb7d847d
function::edit                          9ce5ba1ae4607e8cf1975080bcde1cf4
function::enable                        7de1cedc36841f5de8f9fdfbc3b65097
function::export                        2374cd1dbf7616cb38cafba4e171075d
function::extern                        1290a5223e2824763eecfb3a54961eff
function::grep                          55c3cea8ff4ec2403be2a9d948e59f14
function::hash                          6ee131d093e95b80039b4df9c7c84a02
function::hook                          675cdb98b5dd8567bdd5a02ead6184b5
function::hooks                         3d989899c616f7440429a2d9bf1cc44b
function::identity                      6523885762fcc2f354fc25cf6ed126ce
function::import                        5d0f0634cbd01274f2237717507198a2
function::initial-state                 03d8ed608855a723124e79ca184d8e73
function::is                            41564c8f21b12ab80824ac825266d805
function::load-state                    b6cf278a1f351f316fa6e070359b6081
function::lock                          5d8db258704e6a8623fac796f62fac02
function::ls                            0b310755e747c65bca09508fd9d841f0
function::mv                            4a0e338a6edb89ad1e2c779d51d4d47b
function::name                          955ba2d1fe1d67cd78651a4042283b00
function::parents                       3da9e63b5aae9e2f5dcc946a86d166aa
function::perl                          a0f341ea54391b63b6195e7992b6a686
function::reload                        1589f4cf8374e0011991cb8907afca3e
function::rm                            6f6fd7a6c25558eb469d78ea888f8551
function::save                          778c0e1043b9c6c96fb8f266f8061624
function::save-state                    5af59ebc4ad8965767e4dc106d3b557e
function::serialize                     a19ada2d2558ea9da3a7942fb913e15f
function::serialize-single              aa77af032272f5a2664e21713739a223
function::sh                            1b2f542ca9dd63ad437058b7f6f61aac
function::shb                           7b2685a4041c25bc495816e472bdace5
function::shell                         22d25a32ffc3f2855fb7e2aec77c72fb
function::size                          6cd9a4dd17be87ea2962f8f566a97d11
function::snapshot                      56939a47f2758421669641e15ebd66eb
function::state                         8c68044dccae28f33244d0c7e9e9acfb
function::touch                         3991b1b7c7187566f50e5e58ce01fa06
function::unlock                        b4aac02f7f3fb700acf4acfd9b180ceb
function::update                        ac391dc90e507e7586c81850e7c2ecdd
function::update-from                   631721c4dc30e11b2023a6703cbcef52
function::usage                         5bdd370f5a56cfbf199e08d398091444
function::verify                        0c0cc1dfeab7d705919df122f7850a4f
indicator::cc                           3db7509c521ee6abfedd33d5f0148ed3
indicator::locked                       fc2b4f4ca0d6a334b9ac423d06c8f18c
indicator::state                        7c9d42b8fcee852a80d61c4f119c1239
internal_function::around_hook          7cc876e7c5f78c34654337fc95255587
internal_function::associate            05a75afb70daee635eefec8ae037f593
internal_function::attribute            dd6f010f9688977464783f60f5b6d3dd
internal_function::attribute_is         a33841586c7a83264ba2116937d1c5b6
internal_function::cache                eb9da45580a9ac0882baf98acd2ecd60
internal_function::chmod_self           2035e861eedab55ba0a9f6f5a068ca70
internal_function::dangerous            46c4baaa214ab3d05af43e28083d5141
internal_function::debug_trace          0faf9d9f4159d72dfe4481f6f3607ce1
internal_function::execute              f0924e087d978ff2ab1e117124db3042
internal_function::exported             3ec48f01deefa840b52111f2e3f34749
internal_function::extension_for        9de8261d69cc93e9b92072b89c89befd
internal_function::fast_hash            ee5eba48f837fda0fe472645fdd8899a
internal_function::file::read           e647752332c8e05e81646a3ff98f9a8e
internal_function::file::write          3e290fdcb353c6f842eb5a40f2e575f8
internal_function::fnv_hash             c36d56f1e13a60ae427afc43ba025afc
internal_function::hypothetically       b83e3f894a6df8623ccd370515dfd976
internal_function::internal::main       f31f2945a19a668d92505f114ab29c78
internal_function::invoke_editor_on     5eb976796f0ec172d6ec036116a2f41e
internal_function::is_locked            da12ced6aa38295251f7e748ffd22925
internal_function::namespace            784d2e96003550681a4ae02b8d6d0a27
internal_function::parent_attributes    f6ccfaa982ab1a4d066043981aaca277
internal_function::parent_ordering      57b6da88f76b59f3fed9abfa61280e5e
internal_function::retrieve             8a34d1fe047fe1b40c3d2957c4a789eb
internal_function::retrieve_with_hooks  0f1b0220ccd973d57a2e96ff00458cf2
internal_function::select_keys          a5e3532ec6d58151d0ee24416ea1e2b5
internal_function::separate_options     da1c2a3a1e03faafe6b4446ebb6bad90
internal_function::strip                14f490b10ebd519e829d8ae20ea4d536
internal_function::table_display        d575f4dc873b2e0be5bd7352047fd904
internal_function::temporary_name       6f548d101fc68356515ffd0fc9ae0c93
internal_function::translate_backtrace  d77a56d608473b3cd8a3c6cb84185e10
internal_function::with_exported        df345d5095d5ed13328ddd07ea922b36
library::shell                          378715d20a4a87ee305dd2c3cff1b588
library::terminal                       7e2d045782405934a9614fe04bcfe559
message_color::cc                       2218ef0f7425de5c717762ffb100eb43
message_color::state                    03621cd6ac0b1a40d703f41e26c5807f
message_color::states                   ac66eeeff487b5f43f88a78ea18b3d56
meta::configure                         69c2e727c124521d074fde21f8bbc4db
meta::externalize                       aa44e27e0bbee6f0ca4de25d603a1fc7
meta::functor::editable                 48246c608f363de66511400e00b26164
meta::type::alias                       889d26d2df385e9ff8e2da7de4e48374
meta::type::bootstrap                   51108ab2ddb8d966e927c8f62d9ef3e5
meta::type::cache                       9267171f2eace476f64a1a670eaaf2c7
meta::type::data                        120e1649a468d3b3fd3fb783b4168499
meta::type::function                    8ea626198861dc59dd7f303eecb5ff88
meta::type::hook                        ff92aef328b6bdc6f87ddd0821f3e42f
meta::type::inc                         78e0375b6725487cb1f0deca41e96bbe
meta::type::indicator                   feb54a2624e6983617685047c717427f
meta::type::internal_function           eff3cf31e2635f51c83836f116c99d2f
meta::type::library                     7622e8d65e03066668bade74715d65ad
meta::type::message_color               557a1b44979cbf77a7251fbdc4c5b82c
meta::type::meta                        c6250056816b58a9608dd1b2614246f8
meta::type::parent                      09d1d03379e4e0b262e06939f4e00464
meta::type::retriever                   71a29050bf9f20f6c71afddff83addc9
meta::type::state                       84da7d5220471307f1f990c5057d3319
retriever::file                         3bbc9d8a887a536044bafff1d54def7e
retriever::id                           4da6080168d32445150cc4200af7af6e
retriever::object                       c7633990b4e01bdc783da7e545799f4f
retriever::perl                         f41938e6dbad317f62abffc1e4d28cca

__
meta::parent('preprocessor', <<'__');
function::preprocess           ab5526a02ff417d4c162357dc327e7c4
meta::type::template           bc4b0c80b5efc716b19e99b832c22bf3
parent::object                 1ac66054532268622a9faa98082ee254
retriever::pp                  3b5f5c5d30c5a04f72056dedaacfe7b7
template::comment              dfe273d2dad3d8159b847545e4e5c309
template::eval                 1a0e2124a05056be4abc11803883c294
template::failing_conditional  e3a4523110dd859e828f342185de7c62
template::include              47b5552d609d97fe7f2522d5c1027014
template::pinclude             c07ff79bf8d642cceaa9ef844bfcb189

__
meta::parent('todo', <<'__');
function::parse-todo      c8247ece4f8ea189cd6523b0f94c7247
function::todo-summary    1c986ec8c6efd4dfae2d3ba5e7ca64f2
meta::type::todo          143fa39e155c81f4186aa53a947296ec
parent::./sdoc            cf30ed24cbd679b96e608a6c67dae069
parent::vim-highlighters  b93baa0feaf90f5afc0ab0bed1bd1136

__
meta::parent('vim-highlighters', <<'__');
function::vim                cf9e37026f6cd1499a6dd258fbbcd060
meta::type::vim_highlighter  11a2d74eca3445ee1b7887a6f6370462
parent::object               1ac66054532268622a9faa98082ee254

__
meta::retriever('data-url', <<'__');
use MIME::Base64;
return undef unless $_[0] =~ /^data-url::(.*)$/;
'data:;base64,' . encode_base64(retrieve($1));

__
meta::retriever('file', '-f $_[0] ? file::read($_[0]) : undef;');
meta::retriever('html-sdoc', <<'__');
my ($attribute) = @_;
return undef unless $attribute =~ s/^html::/sdoc::/ and exists $data{$attribute};
sdoc_html($attribute);

__
meta::retriever('http', <<'__');
use LWP::Simple ();
return undef unless $_[0] =~ /^(?:http:)?\/\/(\w+.*)$/;
LWP::Simple::get("http://$1");

__
meta::retriever('id', '$_[0] =~ /^id::/ ? substr($_[0], 4) : undef;');
meta::retriever('object', <<'__');
# Fetch a property from another Perl object. This uses the 'cat' function.
return undef unless $_[0] =~ /^object::(.*?)::(.*)$/ && -x $1 && qx|$1 is '$2'|;
join '', qx|$1 cat '$2'|;

__
meta::retriever('perl', <<'__');
# Lets you use the result of evaluating some Perl expression
return undef unless $_[0] =~ /^perl::(.*)$/;
eval $1;

__
meta::retriever('pp', <<'__');
return undef unless namespace($_[0]) eq 'pp';
my $attr = retrieve(attribute($_[0]));
defined $attr ? preprocess($attr) : undef;
__
meta::retriever('sdoc', 'exists $data{"sdoc::$_[0]"} ? sdoc("sdoc::$_[0]") : undef;');
meta::retriever('sdocp', <<'__');
my $attribute = attribute($_[0]);
exists $data{"sdoc::$attribute"} ? sdocp("sdoc::$attribute") : undef;
__
meta::sdoc('js::kevlar', <<'__');
Kevlar web stuff | Spencer Tipping
Licensed under the terms of the MIT source code license

Introduction.
Kevlar is a bunch of stuff that may or may not be useful to web application developers. There are two main pieces: the client, comprised of a jQuery-based RPC client, and a bunch of stuff for
server-end development. The latter piece includes a basic database, a very simple webserver, and some client/server libraries to handle various kinds of encryption and authentication.

kevlar = caterwaul.js_all()(function (require, deglobalize_function) {
  var kevlar = {deglobalize: deglobalize_function};

- pinclude pp::js::kevlar.server
- pinclude pp::js::kevlar.db

  return kevlar})(require, (function () {var global = typeof kevlar === 'undefined' ? undefined : kevlar; return function () {var k = kevlar; kevlar = global; return k}})());

Client/server extensions.
These modules run on both the client and the server, so they provide their own caterwaul invocations rather than being bundled into the above function. They assume that the kevlar global is
defined.

- pinclude pp::js::kevlar.transport

__
meta::sdoc('js::kevlar.client.jquery', <<'__');
Kevlar jQuery RPC client | Spencer Tipping
Licensed under the terms of the MIT source code license

Introduction.
There are two modes of client operation. By default, kevlar uses a blocking AJAX connection to retrieve the RPC list; this automatically configures the client-side RPC endpoints to give you
named methods. However, sometimes you don't have the luxury of blocking the UI thread this way. In that case you can create a non-auto RPC endpoint.

All methods are attached to a global named kevlar. Like caterwaul, the kevlar global gives you a deglobalize() method to restore the original global.

Note that this module expects a global JSON object to be available. This can be enabled by loading json2.js from json.org, or by using a modern browser that provides native JSON serialization
and parsing.

caterwaul.js_all()(function (original_kevlar) {
  kevlar(xs = arguments) = this.constructor === kevlar ? this : new kevlar() -effect- xs *![it.create_rpc_endpoint_for(x)] /seq,
  kevlar.deglobalize()   = this -re [kevlar = original_kevlar],

  kevlar.prototype.create_rpc_endpoint_for(name) = this -se [it[to_javascript_identifier(name)] = rpc_thunk_for(name, it)],
  kevlar.prototype.auto(cc)                      = this -se- $.ajax({url: '/kevlar/rpc-map', type: 'POST', data: '[]', dataType: 'json',
                                                   success: bgiven.methods in methods[0] *![this.create_rpc_endpoint_for(x)] /seq -effect [cc && cc()]}),

  where [rpc_thunk_for(name, binding)(xs = arguments) = binding -se- $.ajax({type: 'POST', url: '/#{name}', data: JSON.stringify(parameters), dataType: 'json', success: callback})
                                                        -where [parameters = Array.prototype.slice.call(xs),
                                                                callback   = parameters[parameters.length - 1] -re [it && it.constructor === Function ? parameters.pop() : null]],

         to_javascript_identifier(s)                  = s.replace(/[^A-Za-z0-9_$]/g, '_').replace(/_+/g, '_')]})(typeof kevlar === 'undefined' ? undefined : kevlar);

__
meta::sdoc('js::kevlar.db', <<'__');
Kevlar database component | Spencer Tipping
Licensed under the terms of the MIT source code license

Introduction.
This is a fairly straightforward, bomb-proof database designed for easy use, administration, and disaster recovery. All of the contents are stored directly on the filesystem as JSON text
files, and all database operations are stored in a replayable log.

Unlike most databases, kevlar doesn't provide general-purpose tables. Instead, you specify the usage pattern for a collection when you create it. Right now there are two kinds of collections:
associative hashes and append logs. Associative hashes operate like key-value stores, and append logs operate like text files (though they end up being faster due to record partitioning).

Using kevlar databases.
Ease of use is an important prerequisite to having something be bulletproof. Here's how to create and use a database in kevlar:

| $ node
  > var k = require('./kevlar');
  > var test = k.database('test');                              // uses ./test
  > var foo = test.log('foo');                                  // uses ./test/foo
  > var bar = test.associative('bar');                          // uses ./test/bar

Here's the basic idea of using a log:

| > foo(+new Date() % 3600000, 'hi there');                     // appends 'hi there' to the log and uses the current hour as the partition identifier
  > foo.find(+new Date() % 3600000, function (result) {         // iterates over all records in a single partition
      console.log(result);
    });
  > foo.find(function (result) {                                // iterates over all records in all partitions
      console.log(result);
      return false;                                             // stops iteration
    });

And here's what it looks like to use an associative table:

| > bar('bif', 'baz');                                          // associates 'bar' with 'baz'
  > bar.find('bif', function (result) {                         // finds the record associated with 'bif'; if it doesn't exist, your callback is invoked on undefined
      console.log(result);
    });

Each of these calls creates any files or directories that don't already exist.

Indexing stuff.
Any self-respecting database will provide a way to maintain lists of objects that have some property. Kevlar is self-respecting by this definition, but only barely. It doesn't automatically
index things; this is up to you. Here's how you build an index (in this example I'm indexing the first letter of each item in the associative table):

| > var by_letter = test.index('by_letter');                    // create or use an index
  > by_letter.add('b', 'bar');                                  // adds 'bar' to the collection of things starting with b (this operation is idempotent)
  > by_letter.find('b', function (result) {                     // retrieves everything that starts with b
      console.log(result);
      return false;                                             // stops iteration
    });
  > by_letter.remove('b', 'bar');                               // removes 'bar' from the collection of things starting with b

The on-disk format for indexes is a bit complex. There's a great paper by the Tokutek guys that describes what they call 'fractal trees', an indexing strategy that is much higher-performance
than B-trees on disks where seeks are expensive. I may try to implement those for this database, though it will probably be the simplified version presented in their paper rather than the full
version they've released in their TokuDB product.

For the moment I'm deferring indexing support. The priority at the moment is to get basic data storage going.

  (function () {
    kevlar.database(name) = ensure_directory_sync(name) -returning-
                              {log: log_generator_for(name), associative: associative_generator_for(name), hourly_log: hourly_log_generator_for(name)},

    where [fs                                   = require('fs'),
           ensure_directory_sync(name)          = fs.statSync(name) -safely- fs.mkdirSync(name, 0755),

           associative_generator_for(db)(table) = ensure_directory_sync('#{db}/#{table}')
                                                  -returning- result -effect [it.find(name, f) = result -effect- read_contents(name, f)]

                                                      -where [result(name, value)            = result -effect [set_contents(name, value)],

                                                              djb2_hash(s)                   = bind [h = 5381] in s *![h = (x.charAt(0) * 33 + h) >>> 0] /seq -re- h,
                                                              prefix_directory_for(name)     = (djb2_hash(name) & 0xfff).toString(36),
                                                              with_prefix(name, cc)          = fs.stat('#{db}/#{table}/#{dir}', given [err, stat] [
                                                                                                 err ? fs.mkdir('#{db}/#{table}/#{dir}', 0755, given.nothing in cc(dir)) : cc(dir)])
                                                                                               -where [dir = prefix_directory_for(name)],

                                                              pending_changes                = {},
                                                              timeouts                       = {},
                                                              schedule_commit_for(name)      = timeouts[name] || (timeouts[name] = setTimeout(given.nothing in commit(name), 1000)),

                                                              commit(name)                   = write_file_contents(name, pending_changes[name]) -then- delete timeouts[name]
                                                                                                                                                -then- delete pending_changes[name],

                                                              set_contents(name, value)      = pending_changes[name] = value -effect [schedule_commit_for(name)],

                                                              write_file_contents(name, v)   = with_prefix(name, given.prefix in fs.writeFile(tempfile, JSON.stringify(v), 'utf8',
                                                                                                          detect_errors(delay in fs.rename(tempfile, filename,
                                                                                                          detect_errors(delay in null))))

                                                                                                 -where [filename              = '#{db}/#{table}/#{prefix}/#{name}',
                                                                                                         tempfile              = '#{filename}+',
                                                                                                         detect_errors(f)(err) = err -raise -when.err -then- f()]),

                                                              read_contents(name, f)         = name in pending_changes ? pending_changes[name] :
                                                                                               with_prefix(name, given.prefix in
                                                                                                 fs.readFile('#{db}/#{table}/#{prefix}/#{name}', 'utf8',
                                                                                                             given [err, data] [err /wobbly /when.err, f(JSON.parse(data))]))],

           hourly_log_generator_for(db)(table)  = bind [log = log_generator_for(db)(table)] in
                                                  given [thing] [log(now(), thing)] -effect [it.find(bucket, f) = log.find(bucket, f)]
                                                                                     -where [now() = '#{d.getFullYear()}.#{n(d.getMonth() + 1)}#{n(d.getDay())}.#{n(d.getHours())}00'
                                                                                                     -where [d = new Date(), n(x) = x < 10 ? '0#{x}' : x]],
           log_generator_for(db)(table)         = ensure_directory_sync('#{db}/#{table}')
                                                  -returning- result -effect [it.find(bucket, each) = result -effect- read_bucket_contents(bucket, each)]

                                                      -where [result(bucket, stuff)          = result -effect [append_to_bucket(bucket, JSON.stringify(stuff))],

                                                              append_to_bucket(bucket, line) = queue_for(bucket).push(line) -then- schedule_commit_for(bucket),

                                                              timeouts                       = {},
                                                              schedule_commit_for(bucket)    = timeouts[bucket] || (timeouts[bucket] = setTimeout(given.nothing in commit(bucket), 1000)),

                                                              commit(bucket)                 = write_each_queue_item_for(bucket) -then [delete queues[bucket], delete timeouts[bucket]],
                                                              write_each_queue_item_for(b)   = write_stream_for(b).end(queues[b].join('\n') + '\n', 'utf8'),
                                                              write_stream_for(bucket)       = fs.createWriteStream('#{db}/#{table}/#{bucket}', {flags: 'a', mode: 0644}),

                                                              read_bucket_contents(b, f)     = each_line(fs.createReadStream('#{db}/#{table}/#{b}', {encoding: 'utf8'}), f),

                                                              each_line(stream, f)           = stream -effect [it.on('data', given.piece   in got_pieces(piece.split(/\n/))),
                                                                                                               it.on('end',  given.nothing in f(partial) -when- partial.length)]

                                                                                                       -where [partial        = '',
                                                                                                               got_pieces(ps) = f(partial + ps[0])
                                                                                                                                -then- ps.slice(1, ps.length - 1).forEach(f)
                                                                                                                                -then [partial = ps.length > 1 && ps[ps.length - 1]]],
                                                              queues                         = {},
                                                              queue_for(bucket)              = queues[bucket] || (queues[bucket] = [])]]})();

__
meta::sdoc('js::kevlar.server', <<'__');
Kevlar web framework | Spencer Tipping
Licensed under the terms of the MIT source code license

Introduction.
I'm writing kevlar because I want a very simple, reliable way to deploy applications. There are two ideas here. First, a web application is a single HTML page that talks to REST APIs. Second,
some kind of failure is inevitable, so requests and replies should all be logged in a replayable format to minimize data loss.

Interface.
There are exactly two kinds of endpoints. One is the default URL /, which maps to a precompiled HTML page with no external references. The other is an RPC with a URL of the form /foo, where
'foo' represents the name of the function being called. (It can contain arbitrary characters.) All RPC functions follow a JSON-based protocol and have logging and diagnostics built in.

By default, logging happens to the filesystem in date-stamped files that rotate each hour. This can be changed by providing a different LogStream object -- this is like a WriteStream but
simpler. All you have to do is provide three methods: request(), reply(), and error(). The parameters that are given to each of these methods are described below.

Any errors generated by the server are sent as connection IDs to the client. For example, suppose you request '/foo' with invalid JSON. You'll get a reply like this:

| HTTP 400 Bad Request
  Content-Type: text/plain
  Content-Length: ...
  ...
  2011.0601.1242.10092181               // <- This is a connection ID

Each connection has a unique connection ID that can later be used to identify it in the logs. Kevlar provides utilities to search the logs for connections in log files.

  Request parameters.
  Each log entry describes a complete event that happened. Here are the possibilities for request entries:

  | 1. Valid RPC: If the URL matches an RPC endpoint and the data was parseable as JSON, then wait for all of the POST data and return this object:
                                                                {id, url, headers, json, date}.
    2. Invalid RPC because the data can't be parsed:            {invalid: 'json', url, headers, data, date}.
    3. Invalid RPC because the data is too large:               {invalid: 'size', url, headers, data, date}.
    4. Invalid RPC because the method or URL are wrong:         {invalid: 'method', url, method, headers, date}.
    5. Valid page request:                                      {page: true, id, url, headers, date}.

  In cases 2-4, the server replies 400, 413, and 405, respectively. All valid replies are 200.

  Reply parameters.
  The reply() callback is invoked when an RPC endpoint replied to the request successfully. Here are the possibilities:

  | 1. Valid RPC reply: {id, url, json, date, latency}          - In this case, the server replies 200 with content-type application/json
    2. Valid page reply: {id, url, date, latency}               - In this case, the server replies 200 with content-type text/html

  Error parameters.
  The error() callback is invoked when an RPC endpoint is reached but throws an error for some reason or fails to reply before the reply timeout (5 minutes by default). Here are the
  possibilities:

  | 1. Timeout: {id, url, date, latency}                        - In this case the server sends a 503 (service unavailable)
    2. RPC function error: {id, url, error, date, latency}      - In this case the server sends a 500 (internal server error)
    3. Toplevel server error: {error, date}                     - No server reply, since we don't know what caused the error

  Either of these conditions causes a message to be printed to stderr, since they are both abnormal and avoidable.

Creating the HTML page.
The server just looks for a file called 'index.html' in the current directory. If this file exists, it is served for each request to /. Otherwise requesting / returns 404.

Writing an RPC endpoint.
RPC endpoints are just functions that transparently have their arguments JSON-decoded and have their return values JSON-encoded. They are also generally written in CPS. For example, here's how
you might write a 'hello world' application:

| var server = kevlar.server({sayhi: function (name) {
    this('hello ' + name);
  }});
  require('http').createServer(server).listen(8080);

Calling this function using a server-side HTTP client or using the client-side wrapper is straightforward:

| var rpc = kevlar.rpc('sayhi');
  rpc('bob', function (reply) {
    console.log('the server said ' + reply);
  });

You can also use regular AJAX from the browser:

| $.ajaxSetup({contentType: 'application/json'});
  $.post('/sayhi', JSON.stringify(['bob']), function (reply_array) {
    alert('the server said ' + reply_array[0]);
  });

  (function () {
    // Immutable configuration variables
    const reply_timeout_interval  = 300000,
          request_body_size_limit = 1048576;

    // Helper functions
    const next_server_id = given.nothing in Math.random() * 0xffffffff >>> 0;

    kevlar.server(endpoints, options) = handle_request

    -where [requests                      = {},
            responses                     = {},
            timeouts                      = {},
            times                         = {},

            default_options               = {},
            settings                      = caterwaul.merge(default_options, options) -effect [it.log_database || (it.log_database = kevlar.database('kevlar.server.log'))],

            default_rpcs                  = {'/kevlar/rpc-map': given.nothing in this(endpoints /keys /seq)},
            valid_rpcs                    = caterwaul.merge(default_rpcs, endpoints /pairs *[['/#{x[0]}', x[1]]] |object |seq),

            intent_is_rpc(r)              = r.method === 'POST',
            rpc_endpoint_for(url)         = url.charAt(0) === '/' && valid_rpcs[url],

            handle_request(req, res)      = handle_tracked(track(req, res)),
            handle_tracked(id)            = intent_is_rpc(requests[id]) ? handle_rpc(id, rpc_endpoint_for(requests[id].url)) : handle_page(id),
            handle_rpc(id, endpoint)      = endpoint ? handle_rpc_data(id, endpoint) : invalid_method_error(id),
            handle_page(id)               = valid_page_request(id) -then- valid_page_reply(id),

            handle_rpc_data(id, f)        = collect_chunks(id, given.data in parse_and_invoke(id, data, f)),

            parse_and_invoke(id, d, f)    = valid_rpc_request(id, json) -then- f.apply(reply_with_arguments, json)
                                            -when.json
                                            -where  [reply_with_arguments() = valid_rpc_reply(id, Array.prototype.slice.call(arguments)),
                                                     json                   = JSON.parse(d) -safely- invalid_parse_error(id, d) /re [false]]
                                            -safely [rpc_error(id, e)],

            collect_chunks(id, cc)        = requests[id] -effect [it.on('data', given.c [size_ok(c) ? chunks.push(c) : too_big()]),
                                                                  it.on('end',  given.nothing in cc(chunks && chunks.join('')))]

                                                          -where [chunks      = [],
                                                                  size_so_far = 0,
                                                                  too_big()   = invalid_size_error(id, size_so_far) -effect [chunks = null, too_big() = null],
                                                                  size_ok(s)  = (size_so_far += s.length) < request_body_size_limit],

            server_id                     = next_server_id(),
            next_sequence_number          = given.nothing [++n >= 1000000 ? (n = 100000) : n] -where [n = 100000],
            request_id()                  = '#{d.getFullYear()}.#{n(d.getMonth() + 1)}#{n(d.getDate())}.#{n(d.getHours())}#{n(d.getMinutes())}.#{server_id}.#{next_sequence_number()}'
                                            -where [d = new Date(), n(x) = x < 10 ? '0#{x}' : x],

            track(req, res)               = id -effect [requests[id]  = req,
                                                        responses[id] = res,
                                                        times[id]     = +new Date(),
                                                        timeouts[id]  = setTimeout(timeout_error(id), reply_timeout_interval)] -where [id = request_id()],

            clear(id)                     = delete requests[id] -then- delete responses[id] -then- delete timeouts[id] -then- delete times[id],

            reply_with_error(id, code)    = responses[id] -se [it.writeHead(code, {'content-type': 'text/plain'}), it.end(id)]                                          -then- clear(id),
            reply_with_json(id, json)     = responses[id] -se [it.writeHead(200, {'content-type': 'application/json'}), it.end(JSON.stringify(json))]                   -then- clear(id),
            reply_with_page(id)           = responses[id] -se [it.writeHead(200, {'content-type': 'text/html'}), require('fs').createReadStream('index.html').pipe(it)] -then- clear(id),

            request_log_base(id)          = {id: id, url: r.url, headers: r.headers, date: times[id]}                 -where [r = requests[id]],
            reply_log_base(id)            = {id: id, url: r.url, date: +new Date(), latency: +new Date() - times[id]} -where [r = requests[id]],

            request_logger                = settings.log_database.hourly_log('request'),
            error_logger                  = settings.log_database.hourly_log('error'),
            reply_logger                  = settings.log_database.hourly_log('reply'),

            log_request_error(id, stuff)  = request_logger(caterwaul.merge(request_log_base(id), stuff)),
            log_request(id, stuff)        = request_logger(caterwaul.merge(request_log_base(id), stuff)),
            log_reply_error(id, stuff)    = error_logger  (caterwaul.merge(reply_log_base  (id), stuff)),
            log_reply(id, stuff)          = reply_logger  (caterwaul.merge(reply_log_base  (id), stuff)),

            valid_rpc_reply(id, json)     = log_reply(id, {json: json}) -then- reply_with_json(id, json),
            valid_page_reply(id)          = log_reply(id, {})           -then- reply_with_page(id),

            timeout_error(id)()           = log_reply_error(id, {})         -then- reply_with_error(id, 503),
            rpc_error(id, e)              = log_reply_error(id, {error: e}) -then- reply_with_error(id, 500),

            valid_rpc_request(id, json)   = log_request(id, {json: json}),
            valid_page_request(id)        = log_request(id, {page: true}),

            invalid_method_error(id)      = log_request_error(id, {invalid: 'method', method: requests[id].method}) -then- reply_with_error(id, 405),
            invalid_size_error(id, size)  = log_request_error(id, {invalid: 'size',   size:   size})                -then- reply_with_error(id, 413),
            invalid_parse_error(id, data) = log_request_error(id, {invalid: 'json',   data:   data})                -then- reply_with_error(id, 400)]})();

__
meta::sdoc('js::kevlar.transport', <<'__');
Kevlar transport module | Spencer Tipping
Licensed under the terms of the MIT source code license

Introduction.
Most web servers will want to provide some kind of content protection. Sometimes this happens using HTTPS, but that may or may not be necessary depending on the application. I'm implementing
these encryption and hashing functions to provide a non-HTTPS way to do most authentication-related stuff with reasonable security. (I'm also aware that these libraries are available
elsewhere, but I'm reimplementing stuff here for fun. It's fine with me if you want to fork the project to use existing open-source solutions instead of my less-performant versions.)

  caterwaul.js_all()(function () {

Ascii85 encoding.
This is similar to base-64 but achieves a better packing ratio. The idea is to take each 32-bit group of characters (in this case two characters, since a character has 16 bits and I'm too lazy
to do UTF-8 encoding) and arithmetically convert that into five base-85 digits. Each base-85 digit is just ASCII 33 + some number, yielding a high value of 127. This encoder doesn't insert
checksums or add metadata other than the minimal amount of padding necessary to derive the length of the original string. This implementation differs from the one described at
http://en.wikipedia.org/wiki/Ascii85 in that it adds at most one null character, since each character is encoded as 16 bits rather than 8.

  kevlar -effect [
    it.encode85(s) = encoded -where [encode_block(n) = n[5] *[String.fromCharCode(33 + n / powers_of_85[4 - x] % 85)] -seq -re- it.join(''),
                                     padded          = s.length & 1 ? s + String.fromCharCode(0) : s,
                                     encoded_string  = n[0, padded.length, 2] *[encode_block((padded.charCodeAt(x) << 16 | padded.charCodeAt(x + 1)) >>> 0)] -seq -re- it.join(''),
                                     encoded         = s.length & 1 ? encoded_string.substr(0, encoded_string.length - 2) : encoded_string],

    it.decode85(s) = decoded -where [decode_block(n) = String.fromCharCode(n >>> 16) + String.fromCharCode(n >>> 0 & 0xffff),
                                     block_value(s)  = n[6] /[x * 85 + s.charCodeAt(x0 - 1) - 33] -seq,
                                     padded          = s.length % 5 ? '#{s}uu' : s,
                                     decoded_string  = n[0, padded.length, 5] *[decode_block(block_value(padded.substr(x, 5)))] -seq -re- it.join(''),
                                     decoded         = s.length % 5 ? decoded_string.substr(0, decoded_string.length - 1) : decoded_string],

    where [powers_of_85 = n[5] *~[n[1, x + 2] /[x * 85]] -seq]],

SHA-256 hashing.
This is used to sign messages going back and forth, and for password challenges. It's a fairly standard implementation that returns its internal state as a big-endian string of data; my
intention is to use it in conjunction with the above ascii-85 encoder to provide message digests. The constants and algorithm are from the pseudocode at http://en.wikipedia.org/wiki/SHA-256.

Like the other functions in this file, this function treats all characters as being of 16-bit constant width. This results in some of the numbers being different from usual, and all of the
hashes will be different from the same hash on ASCII-encoded text.

  kevlar -effect [
    it.sha256(s) = n[0, p.length, 32] *![h = hash_block(h, p.substr(x, 32))] -seq
                   -re- h *[String.fromCharCode(x >>> 16) + String.fromCharCode(x & 0xffff)] /seq -re- it.join('') -where [h = hs.slice(), p = pad(s)],

    where [hs = [0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19],
           ks = [0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5, 0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe,
                 0x9bdc06a7, 0xc19bf174, 0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da, 0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
                 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967, 0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85, 0xa2bfe8a1, 0xa81a664b,
                 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070, 0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
                 0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2],

           rr(x, bits)       = x >>> bits | x << 32 - bits,
           hash_block(hs, s) = nhs -where [ws  = n[0, 32, 2] *[s.charCodeAt(x) << 16 | s.charCodeAt(x + 1)] -seq -effect-
                                                 n[16, 64]  *![it[x] = it[x - 16] + s0 + it[x - 7] + s1 >>> 0, where [s0 = rr(it[x - 15], 7) ^ rr(it[x - 15], 18) ^ it[x - 15] >>> 3,
                                                                                                                      s1 = rr(it[x - 2], 17) ^ rr(it[x - 2],  19) ^ it[x - 2]  >>> 10]] /seq,

                                           nhs = bind [a = hs[0], b = hs[1], c = hs[2], d = hs[3], e = hs[4], f = hs[5], g = hs[6], h = hs[7]] in
                                                 n[64] *![h = g, g = f, f = e, e = d + t1 >>> 0, d = c, c = b, b = a, a = t1 + t2 >>> 0,
                                                          where [t1 = ks[x] + ws[x] + h + (rr(e, 6) ^ rr(e, 11) ^ rr(e, 25)) + (e & f ^ ~e & g) >>> 0,
                                                                 t2 = (rr(a, 2) ^ rr(a, 13) ^ rr(a, 22)) + (a & b ^ a & c ^ b & c) >>> 0]] -seq
                                                 -re- [a, b, c, d, e, f, g, h] *[hs[xi] + x >>> 0] /seq],

  Length calculation.
  The SHA-256 spec says that we pad the source out to be 448 bits mod 512, then append the 64-bit big-endian length in bits. The padding is a 1 followed by 0 bits. Because this implementation
  uses 16-bit characters, the numbers become 448 / 16 = 28 and 64 / 16 = 4. So we pad out to 28 characters, then add the length to total 32 characters (512 bits).

           pad(s)                = s + String.fromCharCode(0x8000) + padding_characters((28 + 32 - (s.length + 1) % 32) % 32) + big_endian_64(s.length * 16),
           padding_characters(n) = n[n] *[String.fromCharCode(0)] -seq -re- it.join(''),
           big_endian_64(n)      = [0, 0, n >>> 16, n & 0xffff] *[String.fromCharCode(x)] -seq -re- it.join('')]],

HMAC.
Combined with SHA-256 above, HMAC is used to securely sign a message with little possibility of forgery or key retrieval. (http://en.wikipedia.org/wiki/HMAC has more details.) This algorithm
unconditionally hashes the salt (not per the official spec, but this is simpler) and returns the final hash. My key derivation function isn't nearly as rigorous as PBKDF2; once I understand
the security risks more completely I may change it.

  kevlar -effect [
    it.derive_key(password) = n[1000] /[it.sha256(x0 || password)] -seq,
    it.hmac(k, s) = hash(ok + hash(ik + s)) -where [hash = it.sha256, kp = hash(k), ik = n[16] *[String.fromCharCode(kp.charCodeAt(x) ^ 0x5c)] -seq -re- it.join(''),
                                                                                    ok = n[16] *[String.fromCharCode(kp.charCodeAt(x) ^ 0x36)] -seq -re- it.join('')]],

High-level signature of JSON data.
Any JSON object can be signed and independently verified by the server. This is done by generating a signature function that will then wrap your values appropriately. A wrapped value looks
like this:

| {username: 'foo', message: 'plaintext message', signature: 'base85-signature'}

The signature generator automatically JSON-encodes the message to be sent. The verifier automatically JSON-decodes into an object, or returns undefined if the message didn't have a valid
signature.

  kevlar -effect [
    it.signature_verifier(derived_keys)(message)       = it.decode85(message.signature) === it.hmac(derived_keys[message.user], message.message) ? JSON.parse(message.message) : undefined,
    it.signature_generator(username, derived)(message) = {user: username, message: text, signature: it.encode85(it.hmac(derived, text))} -where [text = JSON.stringify(message)]]})();

__
meta::template('comment', '\'\';     # A mechanism for line or block comments.');
meta::template('eval', <<'__');
my $result = eval $_[0];
terminal::warning("Error during template evaluation: $@") if $@;
$result;
__
meta::template('failing_conditional', <<'__');
my ($commands)    = @_;
my $should_return = $commands =~ / if (.*)$/ && ! eval $1;
terminal::warning("eval of template condition failed: $@") if $@;
$should_return;
__
meta::template('include', <<'__');
my ($commands) = @_;
return '' if template::failing_conditional($commands);
join "\n", map retrieve($_), split /\s+/, $commands;
__
meta::template('pinclude', <<'__');
# Just like the regular include, but makes sure to insert paragraph boundaries
# (this is required for SDoc to function properly).

my ($commands) = @_;
return '' if template::failing_conditional($commands);
my $text = join "\n\n", map retrieve($_), split /\s+/, $commands;
"\n\n$text\n\n";
__
meta::todo('bugs', <<'__');
Critical database bugs.
These will cause data loss or something similarly catastrohpic.

| [///] db.critical     mkdir failures are not handled correctly [resolved: now they result in toplevel errors]
  [///] db.critical     values written to an associative table may never be committed to disk [resolved]

__
meta::todo('features', <<'__');
Database todo items.
The database underpins the server project (since the server uses it for logging), so it's fairly high priority.

| [///] db Log table support
  [///] db Associative table support
  [   ] db Indexing support
  [   ] db Integration and unit tests
  [///] db REPL environment

Server todo items.

| [///] server Routing logic
  [///] server RPC implementation
  [// ] server Client page precompiler
  [// ] server Client page server
  [///] server Request/reply logging and integration with kevlar DB
  [   ] server Integration and unit tests
  [///] server REPL environment

Client todo items.

General todo items.

| [///] auth Unencrypted RPC channels
  [   ] auth Signed RPC channels
  [   ] auth Encrypted RPC channels

| [   ] precompiler Add image support via data: urls
  [   ] precompiler Fix <script> tag processing for pathological scripts

__
internal::main();

__END__